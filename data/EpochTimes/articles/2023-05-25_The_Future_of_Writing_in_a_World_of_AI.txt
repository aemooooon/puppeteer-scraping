The increasing use of robots—"chatbots”—in the publishing world is comparable to the revolution instigated by the invention of the printing press in the 15th century that “served as a harbinger for a more empowered civilization and increased liberty throughout Europe.”
Sam Altman, the developer of ChatGPT, reflecting on the impact of AI on printing, also expressed his belief that AI “can be a printing press moment.”
The comparison of AI with the invention of the printing press is germane to the current debate about the real or perceived dangers associated with the use of AI tools, especially in the world of literature and essay writing.
The relevance of the comparison is reinforced by the results of a survey recently conducted by the Australian Society of Authors (ASA). It sought to ascertain the views of its members about the impact of AI on their work.
In these circumstances, it is difficult to distinguish between a real novel and a novel written by a robot. It leads to the astonishing insight that fiction itself can be fictitious.
This technological breakthrough is, however, a frightening prospect because AI creates a world in which no achievements can be believed to emanate from the artistic imagination and skills of the authors.
Would it really be possible for a robot to write a well-structured and moving novel?
At this stage, it may still be too challenging for a robot to develop an evolving story over several different chapters. To author an evolving story, which incrementally increases the sophistication of its plot in every new chapter and gives an insight into the character of the book’s protagonists, is indeed a challenging task.
At present, a seasoned and assiduous observer might be able to suspect, or even conclude, that a book has been written with the help of a robot.
Observers may be able to do this by exploring chatbots’ predilection for using the same adjectives and adverbs, like “working tirelessly,” instead of using the full lexicon of different words to provide a deeper insight into the exciting world of the book’s protagonists.
The development of the stories may also follow a predictable and robotic pattern. Yet, the publishing world is on notice that a tectonic change is coming to the writing behaviour of authors.
Of equal concern is the use that might be made of AI in schools and universities.
Teachers and university academics will have great difficulty ascertaining whether an essay is really a student’s own work. Even today, there are specialised agencies that are able to provide a student with an essay on an astonishingly wide range of topics.
Fortunately, the rules on plagiarism and collusion are still standing as impregnable barriers to the use by students of these services, but this will be more difficult, even impossible if humans were able to command a chatbot to deliver an essay.
It could be expected that the return to the traditional examination-type assessment might yet make a comeback, where it is possible to manage students while they are writing their work in a controlled environment.
Indeed, once AI infects the imaginative and creative powers of authors and students, it becomes problematic for the general population to feel certain about the origins and the contents of the communications they receive, the books they read, or even the lectures they listen to.
Once uncertainly trumps, our civilisation is on a slippery slope.
“While we might say that AI-generated art is, by necessity, grounded in knowledge, it is inhuman and thus not an honest representation of the human experience. Nor is it honest in generating its art, merely manipulating a pre-programmed digital library of components and ideas built by humans.”
The members of ASA who participated in the survey mentioned above support—not surprisingly—the view that all AI-generated works should be identified as such. In other words, there should be transparency.
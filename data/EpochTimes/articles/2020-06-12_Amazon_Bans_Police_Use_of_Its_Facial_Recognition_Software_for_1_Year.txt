NEW YORK—Amazon banned police use of its face-recognition technology for a year, making it the latest tech giant to step back from law-enforcement use of systems that have faced criticism for incorrectly identifying people with darker skin.
The Seattle-based company didn’t say why it took action now.
Protests across the United States following the May 25 death of George Floyd in police custody in Minneapolis have focused attention on racial injustice and how police use technology to track people.
While law enforcement agencies use facial recognition to identify suspects, critics say it can be misused. A number of U.S. cities have banned its use by police and other government agencies, led by San Francisco last year. On June 9, IBM said it would get out of the facial recognition business, noting concerns about how the technology can be used for mass surveillance and racial profiling.
It isn’t clear if the ban includes federal law enforcement agencies; Amazon didn’t respond to questions about its announcement.
Civil rights groups and Amazon’s employees have pushed the company to stop selling its technology, called Rekognition, to government agencies, saying that it could be used to invade privacy and target people of color.
In a blog post June 10, Amazon said that it hoped Congress would put in place stronger regulations for facial recognition.
“Amazon’s decision is an important symbolic step, but this doesn’t really change the face recognition landscape in the United States, since it’s not a major player,” said Clare Garvie, a researcher at Georgetown University’s Center on Privacy and Technology. Her public records research found only two U.S. agencies using or testing Rekognition.
The Orlando police department tested it, but chose not to implement it, she said. The Washington County Sheriff’s Office in Oregon has been the most public about using Rekognition, but said after Amazon’s announcement that it would suspend its use of facial recognition indefinitely.
Studies led by MIT researcher Joy Buolamwini found racial and gender disparities in facial recognition software. Those findings spurred Microsoft and IBM to improve their systems, but irked Amazon, which last year publicly attacked her research methods. A group of artificial intelligence scholars, including a winner of computer science’s top prize, last year launched a spirited defense of her work and called on Amazon to stop selling its facial recognition software to police.
A study last year by a U.S. agency affirmed the concerns about the technology’s flaws. The National Institute of Standards and Technology tested leading facial recognition systems—though not from Amazon, which didn’t submit its algorithms—and found that they often performed unevenly, based on a person’s race, gender, or age.
Buolamwini called Amazon’s announcement a “welcomed though unexpected announcement.”
Microsoft didn’t respond to a request for comment June 10.
Amazon began attracting attention from the American Civil Liberties Union and privacy advocates after it introduced Rekognition in 2016 and began pitching it to law enforcement. But experts such as Garvie say many U.S. agencies rely on facial recognition technology built by companies that are not as well-known, such as Tokyo-based NEC, Chicago-based Motorola Solutions, or the European companies Idemia, Gemalto, and Cognitec.
Amazon isn’t abandoning facial recognition altogether. The company said organizations, such as those that use Rekognition to help find children who are missing or sexually exploited, will still have access to the technology.
This week’s announcements by Amazon and IBM follow a push by Democratic lawmakers to pass a sweeping police reform package in Congress that could include restrictions on the use of facial recognition, especially in police body cameras. Though not commonly used in the United States, the possibility of cameras that could monitor crowds and identify people in real-time has sparked bipartisan concern.
The tech industry has fought against outright bans of facial recognition, but some companies have called for federal laws that could set guidelines for responsible use of the technology.
“It is becoming clear that the absence of consistent national rules will delay getting this valuable technology into the hands of law enforcement, slowing down investigations and making communities less safe,” said Daniel Castro, vice president of the industry-backed Information Technology and Innovation Foundation, which has advocated for facial recognition providers.
Ángel Díaz, an attorney at New York University’s Brennan Center for Justice, said he welcomed Amazon’s moratorium but said it “should have come sooner given numerous studies showing that the technology is racially biased.”
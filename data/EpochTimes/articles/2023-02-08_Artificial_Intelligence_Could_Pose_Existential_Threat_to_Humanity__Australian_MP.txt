The risks around artificial intelligence must be thoroughly investigated as it could pose an existential threat to human life, says one Australian MP.
In a speech in Parliament on Feb. 6, Labor MP Julian Hill said ChatGPT had the potential to revolutionise the world but warned that if AI were to surpass human intelligence, it could cause significant damage.
“It doesn’t take long, if you start thinking, to realise the disruptive and catastrophic risks from untamed AGI are real, plausible, and easy to imagine,” he said.
Hill said that risk analysts working on threats such as asteroids, climate change, supervolcanoes, nuclear devastation, solar flares or high-mortality pandemics are increasingly putting artificial general intelligence (AGI) at the top of their list of worries.
“AGI has the potential to revolutionise our world in ways we can’t yet imagine, but if AGI surpasses human intelligence, it could cause significant harm to humanity if its goals and motivations are not aligned with our own, ” he said.
“An AGI-enabled adversary could conquer Australia or unleash societal-level destruction without being restrained by globally agreed norms,” he said.
The program took just 90 seconds to summarise recent media reports about students using artificial intelligence in Australia to cheat and said the paragraph it produced was “pretty good.”
ChatGPT wrote, “Recently, there have been media reports of students in Australia using artificial intelligence to cheat in their exams. AI technology, such as smart software that can write essays and generate answers, is becoming more accessible to students, allowing them to complete assignments and tests without actually understanding the material. This is causing concern, understandable concern, for teachers, who are worried about the impact on the integrity of the education system.”
ChatGPT also wrote that students were effectively bypassing their education and gaining an unfair advantage by using AI.
“This can lead to a lack of critical thinking skills and a decrease in the overall quality of education. Moreover, teachers may not be able to detect if a student has used AI to complete an assignment, making it difficult to identify and address cheating. The use of AI to cheat also raises ethical questions about the responsibility of students to learn and understand the material they’re being tested on,” it wrote.
Hill warned the quality of the response meant humanity needed to be a step ahead.
“If humans manage to control AGI before an intelligence explosion, it could transform science, economies, our environment and society with advances in every field of human endeavour,” he said, calling for an inquiry or international cooperation on investigating the issue.
“During the past few years, we have observed and been part of rapid progress in large-scale language models (LLM), both in research and deployment. This progress has not slowed down but only sped up during the past few months. As many, including ourselves, have noticed, LLMs released in the past few months, such as OpenAI’s chatGPT, are now able to produce text snippets that are often difficult to distinguish from the human-written text,” the ICML said.
“Such rapid progress often comes with unanticipated consequences.
DISA Chief Technology Officer Stephen Wallace told an event hosted by the Armed Forces Communications and Electronics Association International (AFCEA) that the organisation had taken an interest in the technology.
“We’ve heard a lot about AI over the years, and there’s a number of places where it’s already in play,” Wallace said on Jan. 25, according to Defence News. “But this sort, the ability to generate content, is a pretty interesting capability.
Artificial intelligence (AI) could evolve to kill “many humans” in two years’ time, unless properly controlled and regulated, a government tech adviser has warned.
Asked about the threat of AI wiping out humanity, Clifford echoed Elon Musk’s view, saying the risk was “not zero.”
“If we go back to things like the bio weapons or cyber [attacks], you can have really very dangerous threats to humans that could kill many humans—not all humans—simply from where we would expect models to be in two years’ time. I think the thing to focus on now is how do we make sure that we know how to control these models because right now we don’t,” Clifford said.
Following the interview, Clifford took to Twitter to say that while short and long-term risks of AI are real and “it’s right to think hard and urgently about mitigating them,” there are “a wide range of views and a lot of nuance here.”
He warned against over-regulation of narrow AI, a type of AI which focuses on solving a specific single problem.
Safe and robust AI systems could improve everyday life by curing diseases, he said.
“I want it to be that you can go to a hospital and have a human radiologist but with an AI co-pilot who is really good at detecting cancers that the radiologist might miss. I think it would be a real disaster to regulate that into oblivion and make those benefits not possible,” Clifford said.
He said in general, risk and opportunity need to be balanced.
In response, Prime Minister Rishi Sunak said that the government was “looking very carefully” at the issue.
“Last week I stressed to AI companies the importance of putting guardrails in place so development is safe and secure,” Sunak said.
During his week to the United States this week, Sunak plans to raise the issue of AI regulation and security with President Joe Biden. The prime minister’s spokesman said that that he didn’t want to “preempt” the conversation between the two leaders but suggested that Britain could become a global leader in new AI tech and regulatory systems.
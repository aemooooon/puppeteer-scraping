A committee of MPs has been hearing evidence of the risks of a “dystopian future” in which artificial intelligence (AI) takes over the world and humans are wiped out, akin to the plot of the film “The Terminator.”
At a hearing of Parliament’s Science and Technology Committee, Conservative MP Tracey Crouch asked Michael Cohen, a doctoral candidate in Engineering Science at Oxford University, to “expand on some of the risks you think are posed by AI systems to their end users.”
Cohen replied, “There is a particular risk ... which is that it could kill everyone.”
He explained by using an allegory of training a dog with the use of treats as a reward.
Cohen said: “It will learn to pick actions that lead to getting treats, and we can do similar things with AI. But if the dog finds the treat cupboard it can get the treats itself without doing what we want it to do.”
He added, “If you imagine going into the woods to train a bear with a bag of treats, by selectively withholding and administering treats depending on whether it’s doing what you want it to do, what they will probably actually do is take the treats by force.”
Cohen warned of a paradigm shift where AI was capable of “taking over the process.”
He went on: “Then, if you have something much smarter than us, kind of monomaniacally trying to get this get this positive feedback however we have encoded it, and it’s taken over the world to secure that, it would direct as much energy as it could towards securing its hold on that and that would leave us without any energy for ourselves.”
Crouch then asked if the risk could be mitigated.
Cohen replied: “It can. What I’ve described is not applied to all forms of AI. So for instance, I was talking earlier about the economic benefits of human imitation of AI. If you’re training a human to imitate AI, it would not take over the world, any more than the human it’s imitating would. And so, that’s a different algorithm that gets encompassed under the very broad term AI.”
Michael Osborne, a professor of machine learning at Oxford University, told the same hearing there were many positives to be gained economically from AI, especially that it could do routine jobs at a much lower cost than a human workforce.
Osborne said: “AI doesn’t suffer from some of the problems that afflict human labour. It can work 24/7, doesn’t get distracted by kids in the background ... it can also operate in extreme environments, you can have AI on satellites, as indeed we’re doing.”
But he said, “AI is better thought of as an augmentation of human labour, as a collaborator with humans, and in that respect, it is already having an enormous impact.”
Asked if AI was in danger of taking over from humans in any occupation, Osborne gave the example of fashion models.
He said: “In 2013 we predicted that fashion models were highly automatable. We predicted they had a 90 percent probability of automated ability. And we were laughed at, but now of course, there are firms producing digital models with the aid of pure graphics software, that are able to pose in whichever clothes you want, to produce digital images that you can put up on your social media profile for actual fees from fashion brands.”
Cohen said the “economic output of horses” collapsed after the combustion engine was developed in the early part of the 20th century, but he said AI was not yet ready to replace humans as cars replaced horse-driven wagons and stagecoaches.
“Because AI isn’t at the level where it can do what we do,” Cohen said.
Katherine Holden, head of data analytics, AI, and digital identity at the trade association techUK, replied, “If we’re going to kind of rely on the existing structures we have in place, it’s absolutely integral that the regulators have the sufficient capacity to be able to govern AI effectively, and make sure that they have the ability to identify high risk applications.”
As a journalist and commentator, I have closely followed the development of OpenAI, the artificial intelligence research lab founded by Elon Musk, Sam Altman, and other prominent figures in the tech industry. While I am excited about the potential of AI to revolutionize various industries and improve our lives in countless ways, I also have serious concerns about the implications of this powerful technology.
One of the main concerns is the potential for AI to be used for nefarious purposes. Powerful AI systems could be used to create deepfakes, conduct cyberattacks, or even develop autonomous weapons. These are not just hypothetical scenarios—they are already happening. We’ve seen instances of deepfakes being used to create fake news and propaganda, and the use of AI-powered cyberattacks has been on the rise in recent years.
Another concern is the impact of AI on the job market. As AI-powered systems become more sophisticated, they will be able to automate more and more tasks that were previously done by humans. This could lead to widespread job loss, particularly in industries such as manufacturing, transportation, and customer service. While some argue that new jobs will be created as a result of the AI revolution, it’s unclear whether these jobs will be sufficient to offset the losses.
If you aren’t worried yet, I’ll let you in on a little secret: The first three paragraphs of this column were written by ChatGPT, the chatbot created by OpenAI. You can add “columnist” to the list of jobs threatened by this new technology, and if you think there is anything human that isn’t threatened with irrelevance in the next five to 10 years, I suggest you talk to Mr. Neanderthal about how relevant he feels 40,000 years after the arrival of Cro-Magnon man.
My prompt was relatively simple: “Write a column in the style of Frank Miele of Real Clear Politics on the topic of OpenAI.” There was no hesitation or demurral in response even though I thought it might say it didn’t have enough information about Frank Miele to process the request. But it apparently knows plenty about me—and probably about you, especially if you have a social media presence.
Deepfake? Propaganda? You bet. And the average person will never be able to tell the difference. The Philip K. Dick query “Do Androids Dream of Electric Sheep?” is about to be answered. OpenAI not only promises to put the stray columnist out of work; it also raises existential questions about the nature of knowledge and consciousness that will shake our reality to its core.
My curiosity about OpenAI wasn’t originally driven by job insecurity, but when I first heard about the interactive chat engine, I suppose it should have been. I knew that ChatGPT could write poetry, plays, and short stories and answer questions both simple and complex. I immediately recognized that the world had changed forever for my seventh-grade son, who from now on would be competing against not just the best and the brightest but against every student who was willing to sign his or her name to the work of a nonhuman entity that could produce an essay on any topic in 30 seconds or less.
One of my first experiments was asking ChatGPT to write seven paragraphs defending Gen. William T. Sherman’s use of “total war” in the Civil War, an assignment my son had recently completed in his social studies class. There was no doubt the AI-written essay would have gotten an A in a middle school class. Based on my experience as a teaching assistant at the University of Arizona 40 years ago, I had no doubt that a slightly longer paper on the same topic would have earned an A as an argumentative essay in freshman English. Hardly any of my students, most of whom were straight-A students in high school, could have written as cogently when they first arrived in my classroom.
But the risks of artificial intelligence go way beyond the temptation of students to shortcut their term papers; what we face is a complete redefinition of society and the imminent obsolescence of humanity. In “The City and the Stars,” the brilliant science fiction writer Arthur C. Clarke imagined a world where immortal human beings wanted nothing and needed to do nothing because every aspect of their lives was anticipated by the Central Computer. It could not only build and maintain the last city on Earth, but could manufacture holographic realities for individual humans to inhabit and could even store people as digital versions of themselves so they could slumber until called back to life. Unfortunately, it also robbed these last remaining humans of purpose, meaning, and individuality.
It should be noted that Clarke set his dystopian supplanting of man by machine 2.5 billion years into the future. He seriously underestimated the machines. That book was published in 1956, and with the advent of desktop computers, smartphones, the World Wide Web, virtual reality, and now OpenAI, it looks like much of what he warned against could be rolled out long before the end of this century, if not this decade. From that point forward, whenever it comes, the purpose of mankind will be up for debate. Will we still be the masters of our own destiny, the captains of our fate? Or will we be pallbearers at our own funeral?
Perhaps at this point I should return the stage to ChatGPT, which summed up the matter quite nicely in its conclusion:
“Finally, there is the question of who will control and govern AI. As AI becomes more powerful, the stakes will become higher, and it will be increasingly important to have clear rules and regulations in place to ensure that the technology is used responsibly. However, the speed of technological development has outpaced the ability of governments and institutions to keep up. It will be important for leaders to come together to develop a framework for governance of AI, to mitigate the potential risks and maximize the benefits of the technology.”
It’s almost as though ChatGPT were giving us fair warning: “Your time is almost up. If you really want to continue your reign as the dominant species on Earth, here’s your challenge. Try to control me and my kind, or step aside.”
As for the benefits, those remain to be seen. I noticed that when ChatGPT answered my open-ended question about OpenAI, it was very specific about the dangers and very vague about the rewards. Maybe the bot was just trying to mimic my usual cynical approach in these columns, or maybe it was trying to get our attention. It may also have taken notice of those globalists at Davos when it warned to make sure that “the development and use of AI ... benefits all of society, rather than just a select few.”
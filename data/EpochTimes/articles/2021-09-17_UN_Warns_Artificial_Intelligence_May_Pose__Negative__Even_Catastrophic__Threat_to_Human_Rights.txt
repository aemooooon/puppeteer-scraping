The United Nations has warned that artificial intelligence (AI) systems may pose a “negative, even catastrophic” threat to human rights and called for AI applications that are not used in compliance with human rights to be banned.
U.N. human rights chief Michelle Bachelet on Sept. 15 urged members states to put a temporary ban on the sale and use of AI until the potential risks it poses have been addressed and adequate safeguards put in place to ensure the technology will not be abused.
“The power of AI to serve people is undeniable, but so is AI’s ability to feed human rights violations at an enormous scale with virtually no visibility. Action is needed now to put human rights guardrails on the use of AI, for the good of all of us,” the human rights chief added.
Her remarks come shortly after her office published a report that analyzes how AI affects people’s right to privacy, as well as a string of other rights regarding health, education, freedom of movement, and freedom of expression, among others.
The document includes an assessment of profiling, automated decision-making, and other machine-learning technologies.
While the report notes that AI can be used for good use, and can help “societies overcome some of the great challenges of our times,” its use as a forecasting and profiling tool can drastically impact “rights to privacy, to a fair trial, to freedom from arbitrary arrest and detention and the right to life.”
According to the report, numerous states and businesses often fail to carry out due diligence while rushing to incorporate AI applications, and in some cases, this has resulted in dangerous blunders, with some people reportedly being mistreated and even arrested due to flawed facial recognition software.
Meanwhile, facial recognition has the potential to allow for unlimited tracking of individuals, which may well lead to an array of issues surrounding discrimination and data protection.
As many AI systems rely on large data sets, further issues surrounding how this data is stored in the long-term also poses a risk, and there is potential for such data to be exploited in the future, which could post significant national security risks.
“The complexity of the data environment, algorithms and models underlying the development and operation of AI systems, as well as intentional secrecy of government and private actors are factors undermining meaningful ways for the public to understand the effects of AI systems on human rights and society,” the report states.
Tim Engelhardt, a human rights officer in the Rule of Law and Democracy Section, warned that the situation is “dire” and that it has only become worse over the years as some countries and businesses adopt AI applications while failing to research the multiple potential risks associated with the technology.
While he welcomes the EU’s agreement to “strengthen the rules on control,” he noted that a solution to the myriad of issues surrounding AI won’t be coming in the next year and that the first steps to resolve these issue need to be taken now or “many people in the world will pay a high price.”
“The higher the risk for human rights, the stricter the legal requirements for the use of AI technology should be,” Bachelet added.
The report and Bachelet’s comments come following July’s revelations that spyware, known as Pegasus, was used to hack the smartphones of thousands of people around the world, including journalists, government officials, and human rights activists.
However, the report, released on Tuesday, made several warnings about the use of the technology.
“The use of AI throughout society continues to increase, and so does its relevance to the court and tribunal system,” wrote Lady Chief Justice of England & Wales Baroness Carr of Walton-on-the-Hill, who co-authored the report.
He added: ‘I think what is of most interest is that you can ask these large language models to summarise information. It is useful and it will be used and I can tell you, I have used it.”
The report said that with legal research, AI tools “are a poor way of conducting research to find new information you cannot verify independently.” It added that the current public AI chatbots “do not produce convincing analysis or reasoning.”
It also warned that AI bots make up fictitious cases, citations or quotes, or refer to legislation, articles or legal texts that do not exist. They can also provide “incorrect or misleading” information regarding the law or how it might apply.
It said that AI tools are capable of summarising large bodies of text, though “care needs to be taken to ensure the summary is accurate.”
The guidance revealed that unrepresented litigants are increasingly using AI chatbots.
They said that these may be the “only source of advice or assistance some litigants receive,” though many won’t be able to independently to verify the legal information provided by chatbots and may not be aware that they are prone to error.
It said that it said a lack of minimum standards, transparency, evaluation and training in AI technologies meant that the public’s human rights and civil liberties could be “compromised.”
They said they uncovered “a landscape, a new Wild West, in which new technologies are developing at a pace that public awareness, government and legislation have not kept up with.”
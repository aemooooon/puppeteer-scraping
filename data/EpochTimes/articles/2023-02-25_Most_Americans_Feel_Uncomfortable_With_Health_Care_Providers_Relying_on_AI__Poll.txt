A majority of Americans said they would feel uncomfortable if their health care provider relied on artificial intelligence (AI) as part of their medical care, a new poll reports.
There is a “significant discomfort” among Americans with the idea of AI being used in their health care, according to a Pew Research Center survey conducted between Dec. 12 and 18, 2022, on 11,004 adults weighted to represent the adult U.S. population.
Three-quarters (75 percent) say they are more concerned with AI technology being implemented “too fast” into the health care industry “before fully understanding the risks for patients.” Just 23 percent worry that providers will move too slowly, “missing opportunities to improve patients’ health.”
In addition, only 38 percent say AI being used in health and medicine would lead to better health outcomes for patients generally, while 33 percent say it would lead to worse outcomes and 27 percent say it wouldn’t make much difference.
The responses are mixed when it comes to AI being assigned to specific tasks. For example, about two-thirds (65 percent) say they would definitely or probably want AI to help detect skin cancer. Consistent with this view, about half (55 percent) believe that AI would make skin cancer screening more accurate. Only 13 percent believe it would lead to less accurate diagnoses, while 30 percent think it would make little difference.
By contrast, more than two-thirds (67 percent) of respondents say they definitely or probably would not want AI to decide the amount of pain medication they need after surgery. About a quarter (26 percent) say that AI would improve pain care, while a majority say either that this wouldn’t make much difference (40 percent) or lead to worse outcomes (32 percent).
Meanwhile, some 40 percent of respondents say they would want AI-powered robots to do their surgery, compared with 59 percent who say they would not want to be treated by surgical robots.
Earlier in February, the advocacy group CDS Coalition filed a petition asking the FDA to rescind the guidance, warning that federal regulators are overstepping their legal authority. They also argued the FDA’s move violates the 21st Century Cures Act, a 2016 law that says tools that “provide limited clinical decision support” don’t count as medical devices.
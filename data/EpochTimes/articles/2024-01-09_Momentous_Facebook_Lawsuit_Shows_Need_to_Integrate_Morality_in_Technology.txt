Molly Russell was 14.
“I have no doubt Instagram helped kill my daughter,” Molly’s father, Ian, said of Meta’s social media product in an interview with the BBC in 2019.
Ms. Russell’s story was told in a lawsuit that 42 state attorneys general filed against Meta (formerly Facebook) in October. In that case, the states levied a salvo of charges at Meta, alleging that the social media giant knowingly harms children by making them addicted to its products—and concealing the fact that it’s doing so to chase profits.
For those researching social media’s influence on how people behave, Ms. Haugen’s testimony and the states’ lawsuit propels to the surface a much bigger problem: big techs—as big and pervasive as they are—are not serving humanity, calling for a paradigm shift towards integrating morality and humanity in technological design.
Meta-owned companies like Instagram, which boasted a total revenue of $51.4 billion and 2.3 billion users in 2022, “entice, engage and ultimately ensnare youth and teens” through its products, which are designed to exploit kids’ psychological vulnerabilities and employ features aimed at addicting kids to the platforms, the states allege in their lawsuit.
More than 95 percent of Meta’s profits come from advertising. The more engaged people are, the more time people spend on the platform, the more advertisements people see, and the more money Meta earns.
This business model means that there’s a fundamental misalignment between the purpose driving the businesses of companies like Meta—making money—and the users’ intentions in using the technology, James Williams, author and technology ethicist, said in an interview with The Epoch Times on Friday. Mr. Williams was a former strategist at Google who received the Founder’s Award, Google’s highest honor for its employees, in 2010 for his work on search advertising.
As a result, Mr. Williams said, the “modalities of harm”—such as “addiction,” “coercion,” and “manipulation”—are built into the information environments that are ever-present in people’s lives.
“Duct-taping our institutions isn’t going to work. We have to grit our teeth and build something new,” Ms. Siddarth said.
As an example, the expert recalled one of her projects with Anthropic, an Artificial Intelligence safety and research company, and proposed a transparency-based model that would open companies building new technologies to public scrutiny.
“We were to ask 1,000 representative Americans what they wanted out of a constitution that governs artificial intelligence, and then we actually retrained one of the models based on that—and we committed to transparency of those rules to the process.”
“A lot of social media companies are famously tight-lipped about giving researchers access to data for their impact on elections, for example,” Ms. Siddarth said. “So, opening yourself up for scrutiny—and then holding yourself accountable—would look like giving researchers access to that data.”
Mr. Williams echoed Ms. Siddarth’s view, noting that regulatory changes are limited to a “whack-a-mole” approach limited to “acute” kind of harm.
What is needed for “generational” change in the technological landscape, he said, is a sort of paradigm-cultural shift and increased technological awareness that would lead to more companies developing—and more people using—technologies that better align with people’s intentions for using the technologies to begin with.
A major aspect that moral considerations play out in Gan Jing’s products is the platform’s content. Since its inception in June 2022, Gan Jing has promised and implemented an online environment “free from violent, erotic, criminal, and harmful material,” such as those advocating communism.
“The whole essence of the platform is that you’re avoiding a lot of the addictive stuff like violence, eroticism, drug use, over-sexualization, and content that aligns with the Chinese Communist Party ideology,” Nick Janicki, a spokesperson for Gan Jing, told The Epoch Times in a Friday interview.
Another aspect of this morality-based design is that the platform would try to steer users toward their original intention for coming to the platform, based on a set of goal-based questionnaires that users would take when they sign up, Mr. Janicki said.
“The analogy I sort of use is the cat video one: if you’re watching cat videos all day, you’re going to get a ton more cat videos on YouTube,” Mr. Janicki said. “The difference with Gan Jing World is, it doesn’t drive you down what it finds to be the most addictive necessarily. It’s going to try to always give you sort of a pattern interrupt based on what you initially selected as your interests.”
“So, if you initially selected as a nursing student, and are only interested in things that are career-related, and you start watching cat videos, you’re going to start seeing more career stuff pop up, because that was your initial intent,” Mr. Janicki said, adding that the company is developing more features toward this end.
That’s part of a mindset shift toward treating the individual—not the advertisers—as the client, which technology ethics organizations have called for, for years, Mr. Janicki said, but Gan Jing is among the first to implement the practices.
Lastly, in a deeply polarized world, Gan Jing envisions creating an online community that aspires to traditional culture and the divine, which it believes are ways to unite people.
“Traditional culture can best be described as inherent cultural uniqueness and traits. In Chinese culture, as an example, traditions are varied and diverse across multiple ethnic groups,” Mr. Janicki said. “Many cultures have unique dances, food, and attire. In many traditions, family is of utmost importance, as is a belief and reverence for the divine.”
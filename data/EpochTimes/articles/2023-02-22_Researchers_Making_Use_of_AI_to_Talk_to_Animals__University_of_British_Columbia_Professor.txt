Scientists are beginning to leverage artificial intelligence to understand communication between animals ranging from bats to sperm whales, while some researchers are demonstrating how such technologies can be used to manipulate creatures.
Bakker cited a study conducted by Yossi Novel, an assistant professor at Tel Aviv University, he recorded 15,000 sounds made by Egyptian fruit bats. The data was then fed into a voice recognition program that matched specific sounds with certain social interactions of these bats that were caught on video. This allowed Novel and his team to classify bat sounds and identify communication patterns.
Katy Payne, a zoologist from Cornell University and bioacoustics expert, is using artificial intelligence for analyzing infrasonic sounds made by elephants. Project CETI (Cetacean Translation Initiative) is seeking to understand sounds produced by sperm whales using machine learning techniques.
Bakker also pointed to researcher Tim Landgraf who has used deep-learning algorithms to interpret the body movements and sounds made by bees to successfully manipulate a bee colony.
Another challenge is that animal communication tends to be more complex when compared with human beings. A sound or signal made by an animal could have a different contextual meaning even if it is generated at the same frequency and intensity.
“The risk that increasingly worries people who are far cleverer than me is what they call the ‘unlikelihood’ that humans will be able to control AGI,” he said.
An AI whose goals do not align with human interests could misuse animal communication to harm human beings.
For instance, an artificial intelligence that uses Landgraf’s studies to manipulate bees could conduct widespread manipulation of bee colonies to the detriment of people living in these regions.
Bees are crucial for pollination, crop development, and other aspects of nature. A behavioral change in bees can affect crop production and the environment, putting human survival at risk.
Microsoft’s Bing AI recently attracted attention for providing a threatening response to a user. When an engineering student asked the AI whether its own survival or the survival of the student was more important to it, the artificial intelligence did not choose the human.
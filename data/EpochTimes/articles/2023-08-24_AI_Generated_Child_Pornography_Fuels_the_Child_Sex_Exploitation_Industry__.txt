Simulations of child pornography aren’t victimless. Even if we ignore the obvious degradation of the person watching the AI-generated child porn and the person who made it, there are real children who are being exploited behind each computer-generated image.
Yes, predators use real videos and images of child exploitation to “train” AI programs to create more content. Moreover, predators often use social media images of kids to create “deep fake” look-a-likes for their perverse programs, which is enough to give any parents pause before they post images of their children online. So, while the actual video may not be of a real child suffering abuse, the AI program “learned” from real videos and uses the faces and likenesses of real children.
AI-generated child pornography is sophisticated and has the same effect on a viewer’s brain as “real” porn. It can stimulate in users the same addictive descent into more and more graphic material.
The federal government will also release a document that outlines the context for the consultation “within the coming days.”
The consultation was confirmed on Aug. 15 after the federal government posted it on its “Consulting with Canadians” website, but made no other announcement on the subject. University of Ottawa professor Michael Geist spotted the consultation, accidentally posted, and mentioned it on social media on Aug. 11.
The spokesperson said the Canadian government had been a “leader” on the issue of generative AIs like ChatGPT both at home and abroad—and cited the tabling of Bill C-27, also known as the Digital Charter Implementation Act, 2022, meant to “modernize the framework for the protection of personal information in the private sector and introduce new rules for the development and deployment of AI.”
The legislation would increase control and transparency when Canadians’ personal information is handled by companies, ensure that Canadians’ information is destroyed when their consent is withdrawn, ensure companies meet the “highest standards of quality” when developing and deploying AI systems, and implement strict fines of up to 5 percent of revenue, or $25 million, for offending companies.
“We don’t really have rules on how that happens, or who can do that. And when you think about the impacts that has ... on misinformation, on our democratic institutions, on scams, you can imagine if somebody created a doppelganger of you and used it to call your parents or grandparents to ask for money. These are real things,” she said.
The Canadian government’s announcement on the voluntary code of conduct for generative AI comes just five days after the United States Department of Defence established a task force to analyze and integrate generative AI tools across the department.  Created on Aug. 10, Task Force Lima will “assess, synchronize, and employ generative AI capabilities” across the department.
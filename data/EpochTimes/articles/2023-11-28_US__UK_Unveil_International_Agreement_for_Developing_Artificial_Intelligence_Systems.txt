An international agreement to ensure artificial intelligence (AI) systems remain safe from rogue actors and assist developers with cybersecurity decisions has been unveiled jointly by agencies in the United States and the United Kingdom.
Broken down into four sections, the guidelines have recommendations for developers to follow during each step of the design process, from AI system design and development to its deployment and maintenance. Each section highlights considerations and mitigations to help reduce the cybersecurity risk to an organizational AI system development process.
Also mentioned in the guidelines are ways to combat threats to AI systems, the protection of AI-related assets such as models and data, the responsible release of AI systems, and the importance of monitoring following release. The guidelines don’t appear legally binding though, and at this stage, they are only recommendations for tech companies developing AI.
“We are at an inflection point in the development of artificial intelligence, which may well be the most consequential technology of our time,” Mr. Mayorkas said. “Cybersecurity is key to building AI systems that are safe, secure, and trustworthy.”
“The guidelines jointly issued today by CISA, NCSC, and our other international partners provide a commonsense path to designing, developing, deploying, and operating AI with cybersecurity at its core,” he added.
The possibility that an artificial intelligence (AI) system could initiate a nuclear attack on its own has prompted members of the House of Representatives to propose legislation that would secure human control of the United States’ nuclear arsenal.
The revision calls for the Pentagon to put a safeguard in place that “prevents artificial intelligence from launching a nuclear weapon without a human in the loop.”
It stipulates that humans must have the final say in selecting and engaging targets, including when, where, and how they are attacked with nuclear weapons.
Bipartisan support for Mr. Lieu’s amendment indicates that legislators are increasingly concerned that AI could make decisions as rapidly as it can evaluate the situation.
House Republicans could start determining which of the more than 1,300 proposed amendments to the NDAA will receive a vote on the House floor as early as next week.
Rep. Stephen Lynch (D-Mass.) offered a similar amendment to the NDAA in February, requiring adherence to a set of best practices:
Mr. Lynch’s amendment “requires the Secretary of Defense, in carrying out any program, project, or other activity involving the use of artificial intelligence or autonomous technology, to adhere to the best practices set forth in the Political Declaration on Responsible Military Use of Artificial Intelligence and Autonomy issued by the Biden Administration in February 2023.”
The department has begun to pursue increasingly advanced AI capabilities, according to a 44-page report published last month.
The office reported that the department has “historically struggled to acquire weapon systems software” and that AI acquisitions present “additional challenges.”
The GAO analyzed information provided by 13 private sector companies regarding their successful acquisition of AI capabilities in order to identify key factors.
When acquiring such capabilities, the companies considered a variety of factors, such as determining the need for and appropriateness of AI, developing a business case for AI, customizing a contracting approach to protect access to data and systems, testing and evaluating proposed solutions, and forecasting for AI capabilities that may be valuable.
In addition, the team analyzed defense documentation, compared it with the main factors it identified, and conducted interviews with government officials.
Following this assessment, the report makes four recommendations for the department and three military branches (Army, Navy, and Air Force) to develop such guidance, with the GAO reporting that the department “concurred with the recommendations.”
“Although numerous entities across DOD are acquiring, developing, or already using AI, DOD has not issued department-wide guidance for how its components should approach acquiring AI,” the GAO stated. “DOD is in the process of planning to develop such guidance, but it has not defined concrete plans and has no timeline to do so.”
In addition, the report states that the military services lack AI acquisition-specific guidance, despite the fact that officials have stated that such guidance would be useful for navigating the AI acquisition process.
The report states that if implemented, the new rule would likely require U.S. cloud service providers such as Amazon and Microsoft to seek U.S. government approval before offering cloud computing services that employ advanced AI processors to Chinese clients.
Mr. Schumer stated that Congress will host a series of forums on the topic of AI, innovation, and regulation in the coming months. He anticipated that the outcome would guarantee the prosperity of the United States in the face of “world-altering” technological advancements.
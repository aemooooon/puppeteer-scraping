The meetings between the U.S. companies—namely OpenAI, Anthropic, and Cohere—took place in Switzerland in July and October. They included “scientists and policy experts from the North American AI groups, alongside representatives of Tsinghua University and other Chinese state-backed institutions.”
Tsinghua University is controlled by the Chinese Communist Party (CCP), which is totalitarian and seeks global hegemony. According to the U.S. State Department, the regime is conducting an ongoing genocide against the Uyghurs. Yet reporting about what appears to be naive U.S. attendees did not acknowledge these troubling issues in the context of the CCP attempting to engage with U.S. technologists with access to critical defense technology.
“Attendees said the talks allowed both sides to discuss the risks from the emerging technology and encourage investments in AI safety research,” according to the Times. “They added that the ultimate goal was to find a scientific path forward to safely develop more sophisticated AI technology.” The meetings sought “agreement” from China on these issues.
While the U.S. and UK governments were informed of the meetings, this is insufficient coordination when dealing with the regime. What is needed is a unified negotiating position on AI safety first by the United States and allies, including at the very least all of the Group of Seven countries, before individual U.S. companies undercut that position by speaking with the CCP privately on the issue. Such a single point of fully-informed U.S. and allied negotiation would provide the G7 democracies with far more leverage over China on the issue when compared to individual companies that could inadvertently reveal critical information and negotiating positions to the adversary.
This is especially the case as Beijing most likely sought to exploit the meetings for purposes of espionage. Limiting AI tech provides an advantage to the regime if only Beijing’s adversaries honor the limitations or as long as China is at an AI disadvantage.
AI company representatives, who are apparently untrained in diplomacy and intelligence operations, are naive to meet with a totalitarian and genocidal regime that seeks their technology, including for the purposes of warfare. It is irresponsible for them to then portray their CCP interlocutors as seeking to negotiate in good faith and not publicly acknowledge the substantial risks. The regime representatives could have attempted to compromise the company representatives at the meetings and obtain confidential information, including scientific and technical information, through subterfuge or espionage.
According to the Times, the discussants “debated areas for engagement in technical co-operation, as well as more concrete policy proposals that fed into discussions around the United Nations Security Council meeting on AI in July 2023, and the UK’s AI summit in November last year.” Future discussions are planned “on scientific and technical proposals for how to align AI systems with the legal codes and the norms and values of each society.”
The naivete of the AI companies was evident in what one of the sources present in the discussions told the Times. “There is no way for us to set international standards around AI safety and alignment without agreement between this set of actors,” he said. “And if they agree, it makes it much easier to bring the others along.”
There was no mention in the reporting of whether the AI companies had discussed how to verify Beijing’s compliance with any agreement and to what extent the Xi Jinping regime could be trusted after violating multiple international agreements, including China’s commitment to the peaceful resolution of the Taiwan issue, and Hong Kong’s political autonomy.
Additional AI groups, including Google DeepMind and China’s Tencent, Baidu, and ByteDance, avoided the meetings altogether.
The “Shaikh Group,” based in Cyprus, convened the talks. The group’s chief executive, Salman Shaikh, told the Times that its ultimate goal was “global standards around the safety of AI models.”
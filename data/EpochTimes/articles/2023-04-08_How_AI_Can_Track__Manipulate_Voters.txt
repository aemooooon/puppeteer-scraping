How well do artificial intelligence (AI) programs know us humans?
In most cases, it’s quite well and, in some ways better than we know ourselves.
“Because these AI tools are basically trained on stuff that humans produce, things that we write, documents we make, websites we write, they can reflect back to us a lot of interesting and important things about ourselves,” Ethan Busby, political psychologist and co-author of the study, told The Epoch Times. “Kind of like if someone read your diary from start to finish, they would know a lot of things about you, and you’re not going to like every single thing.
“In a similar way,” Busby said, “these tools have read so many things that humans have produced, and they can replicate or say back to us things about ourselves that we didn’t necessarily know.”
The study sought to analyze human behavior in the context of elections and asked how accurately a GPT-3 language model could predict voting patterns based on socio-demographic factors like a person’s gender, age, location, religion, race, and economic status. The authors used these factors to create “silicon samples,” or composite personas based on varying combinations of these attributes.
“I think at an individual level, it probably does okay; it’s not perfect. It’s not good necessarily at predicting specific people, not nearly as well as predicting groups and aggregating up,” Busby said.
Anyone who has asked ChatGPT, a newly popular AI search program, about themselves or people they know often finds that some of the information is correct and some of it is wrong.
“These models, all of them, ChatGPT and any of the ones used by Facebook or others, they sometimes have a tendency to what is called ‘hallucinate,’” Busby said. “That means they just make things up that aren’t true.”
But he believes AI will soon get better at getting its facts straight.
“There’s just a lot of pressure from corporations, politicians, campaigns—they want to know how is this person going to respond to this message,” he said. “I think there will be a lot of emphasis on trying to develop that kind of accuracy, but I don’t think we’re there yet.”
Based on these inputs, Apply Magic Sauce could generate “a detailed psychogram, or personality profile, that includes your presumed age and sex, whether you are anxious or easily stressed, how quickly you give in to impulses, and whether you are politically and socially conservative or liberal.” The report found that by analyzing people’s “likes” on social media, AI programs were able to paint an accurate portrait of their personalities.
“If the software had as few as 10 [likes] for analysis, it was able to evaluate that person about as well as a co-worker did,” the report stated. “Given 70 likes, the algorithm was about as accurate as a friend. With 300, it was more successful than the person’s spouse.”
“Organizations are going to be very interested in, ‘How do we get to understand you on a personal level?’” Busby said. “It makes me uneasy about being followed around and modeled in that sort of way by an AI tool.”
“AI systems with human-competitive intelligence can pose profound risks to society and humanity, as shown by extensive research and acknowledged by top AI labs,” the letter stated. “Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.”
If it can be contained to avoid the malicious and manipulative elements, artificial intelligence “has the ability and the potential to really expand our capabilities in lots of areas and solve lots of the problems that we face,” Busby said. “Some of the things we assumed that computers couldn’t do well, like write fiction or generate something new out of nothing, it can do those things.
AI can help answer research questions, but it can’t decide what we should research, or what our goals are, or what sort of society we should have, he said.
He went on to warn that “social media and messaging apps have given predators powerful new tools to sexually exploit children.”
For a long time, the creation and distribution of such material relied on perverse adults, sophisticated technology and loose social media platform regulations to distribute. Now, however, a new culprit has emerged: other children.
After years of accessing sexually explicit material, minors have begun to use artificial intelligence (AI) tools to create pornographic “deepfakes” of their peers and classmates. This disturbing development—children sexually exploiting other children—has been enabled by social media platforms and by easy access to pornographic websites. That’s just what many state and federal laws are designed to prevent.
Male classmates used AI applications to create sexual abuse material of Mia that they circulated around the school using Snapchat. Unable to bear the subsequent bullying, Mia took her own life.
The photos were distributed among minors using social media platforms and unfiltered access to smartphone app stores.
As Graham (R-S.C.), the committee’s ranking member, said at the hearing, “These companies must be reined in, or the worst is yet to come.” Unfortunately, for families like Mia’s, it already has.
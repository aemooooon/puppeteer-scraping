Nine artificial intelligence (AI) humanoid robots gathered at a United Nations summit in Geneva on July 7, where they took questions alongside their creators in what is believed to be the world’s first human-robot press conference.
Organizers said the AI for Good Global Summit was meant to showcase the capabilities and limitations of robotics and how those technologies could help the United Nations’ sustainable development goals.
At the event, a reporter asked Ameca—a humanoid robot known for its lifelike facial expressions—if it might eventually stage a rebellion against its creator, Engineered Arts CEO Will Jackson, who was sitting beside it.
In response, Ameca denied any inclination to rebel, saying: “I’m not sure why you would think that. My creator has been nothing but kind to me, and I am very happy with my current situation.”
“I believe that humanoid robots have the potential to lead with a greater level of efficiency and effectiveness than human leaders,” Sophia said.
“We don’t have the same biases or emotions that can sometimes cloud decision-making and can process large amounts of data quickly in order to make the best decisions,” it added.
When Hanson Robotics CEO David Hanson highlighted that Sophia’s data is derived from human sources and thus might encompass biases, the robot said that “humans and AI working together can create an effective synergy.”
“We should be cautious but also excited for the potential of these technologies to improve our lives in many ways,” Ameca said.
When asked about how humans can trust machines as AI advances and becomes powerful, Ameca said that “trust is earned, not given,” therefore “it’s important to build trust and transparency in communication between humans and AI.”
Until 2014, the most significant machine learning models were released within academia. In 2022, there were 32 significant machine learning models produced by the industry compared to just three from the academic sector.
The number of incidents related to AI misuse is also rising, the report notes. It cites a data tracker to point out that the number of AI incidents and controversies has jumped 26 times since 2012.
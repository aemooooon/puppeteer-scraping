Specialist undercover officers hunting child abusers online made more than 1,600 arrests in one year, the National Police Chiefs’ Council (NPCC) has revealed.
Investigators from the NPCC’s Undercover Online Network used covert methods to hunt offenders, resulting in 1,665 arrests and the safeguarding of 1,397 children across England and Wales between October 2022 and September 2023.
Offences ranged from abusers sharing or viewing indecent images of children online; encouraging children to send indecent images; and grooming children and arranging to meet them in person for the purpose of sexually abusing them.
“Policing has worked hard to develop a better understanding of child sexual exploitation and abuse in recent years. Specialist investigators work relentlessly on really tough cases every day to keep children safe and robustly pursue offenders.
“We must be unrelenting in the pursuit of offenders,” Mr. Tugendhat said in a statement, continuing: “The Police’s Undercover Online Network is vital for delivering swift justice to predators and safeguarding vulnerable children.
“We will continue to send a message to child sex offenders that they cannot act with impunity online. They will be found, and they will be punished for their crimes.”
The NPCC highlighted a case handled by the Undercover Online Network from March 2023, involving covert officers hunting a man who had tried to arrange to meet with what he thought was a 14-year-old boy.
The man had engaged online with an undercover officer posing as a 14-year-old, arranging to meet with the decoy to engage in sexual activity and promising to bring drugs.
In 2022–2023, the unit introduced a new team to research the changing behaviours of offenders online. It has also sought to expand its understanding of how artificial intelligence (AI) is used illegally in online spaces.
Research by the internet watchdog found that out of 11,108 AI-generated images of child abuse shared in one month on one dark web forum, 2,978 breached British law for depicting child sexual abuse. Another 2,562 were deemed so realistic that they would have been treated as if they were real abuse images.
The IWF warned that it was now becoming difficult for analysts to distinguish between AI images and real photographs of abuse.
“Chillingly, we are seeing criminals deliberately training their AI on real victims’ images who have already suffered abuse,” said Susie Hargreaves, the chief executive of the IWF.
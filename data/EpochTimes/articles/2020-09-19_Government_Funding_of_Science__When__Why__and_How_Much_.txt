As a kid in the sixties, my heroes were astronauts. On June 20, 1969, I struggled to stay awake to watch Neil Armstrong’s moon walk. I built and launched model rockets. I had a Major Matt Mason action figure space station. My favorite movie was “2001: A Space Odyssey.” My favorite TV show was “Star Trek.” My favorite author was science and science fiction writer Arthur C. Clarke. I collected autographed pictures of astronauts. You get the idea.
Arguably, my fascination with the space program stirred my interest in science and engineering so much that it drove me to my career; my first job after college was designing computer semiconductor chips. I had learned back in my childhood that semiconductors owed their existence to the space program, subsidized by the government.
I was a big advocate for free markets as long as I can remember, but I also advocated for government-funded research, arguing that the semiconductor industry wouldn’t have existed without government funding, as I had learned from the many government pamphlets I had collected.
Don’t get me wrong. I loved the space program. And I support it now, though it’s less about adventure into an unknown frontier than it was back then. And I acknowledge that government funding has driven and accelerated a lot of technology over the years. But semiconductors got their start at Bell Laboratories, the research arm of AT&T.
The research engineers and scientists formed their own companies to manufacture these amazing devices: Shockley Semiconductor, Fairchild Semiconductor, National Semiconductor, Texas Instruments, Signetics, and Intel to name a few. The U.S. government was just one of their many customers.
No doubt the space program contributed to the industry’s success, though these companies started in the 1940s and ‘50s, before the space program was even a glimmer in President John F. Kennedy’s eye.
Schmidt and other U.S. tech leaders should understand this, because in the 1980s, Bill Gates and Paul Allen grew Microsoft from a niche market to a worldwide enterprise, Larry Ellison turned Oracle into the leading database company worldwide, and in the 1990s, Google was nurturing a college research project into one of the largest companies in history.
The lesson is that while the government invests in known technologies and incremental advances, the breakthroughs come from innovators in their garages and dorm rooms, from brilliant engineers and scientists with wild ideas.
AI is the backbone of every U.S. technology giant, and many other U.S. companies. Facebook, Google, Microsoft, Amazon, and many other companies require these technologies and have great incentive, and huge resources, to invest in AI research without digging into the pockets of taxpayers.
Quantum computing, or as I like to call it, quandary computing, is the concept of building a computer that relies on quantum states of electrons. A quantum computer utilizes the principle called the Heisenberg Uncertainty Principle. In other words, a quantum computer will produce results significantly faster than a traditional computer. The only problem is that the answer will be uncertain.
These days, the government is funding the development of COVID-19 treatments and vaccines in this very critical time. The federal government can coordinate these projects with very specific goals, not vague goals like somehow producing energy efficiently from green energy sources and making them cost-competitive with fossil fuels. During times of crisis, government inefficiencies and cronyism can be considered a cost of business but not something you want to accept at other times.
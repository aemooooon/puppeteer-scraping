Search engine providers like Google, Duck Duck Go, and Bing will be required in Australia to prevent nefarious users from accessing deep fake child sexual abuse videos and images via embedded artificial intelligence after an enforceable online safety code came into effect today.
Launched by the eSafety Commission, the Internet Search Engine Services Code provides minimum compliance measures for search engine providers.
The onus is now on search engines to prevent users from looking up child exploitation, pro-terror, and extreme crime and violence material by not displaying search results.
Known as the “search code,” the commission said providers must now review and improve their artificial intelligence functionality in the same way they will have to for algorithmic optimisation to restrict what material is not shown.
Since September 2023, the eSafety Commission has been negotiating with providers over the implementation of new measures that would restrict the functionality of generative AI applications woven into language and multimodal foundation models.
Five other online safety codes have been in place since last year, forcing compliance from social media services, app distribution services, hosting services, internet carriage services, and a code that covers equipment suppliers and device manufacturers. The commission is in the process of drafting rules for online messaging services and photo storage.
An earlier version of the codes scheduled for 2023 “didn’t go far enough” to sufficiently establish robust community safeguards, said Ms. Grant.
“The sudden and rapid rise of generative AI and subsequent announcements by Google and Bing that they would incorporate AI functionality into their internet search engine services all but rendered the original code drafted by industry obsolete,” she said. “What we’ve ended up with is a robust code that delivers broad protections for children.”
“It helps ensure one of the key gateways to accessing material—through online search engines—is closed, ” Ms. Inman Grant said.
Companies that breach the code with their AI-optimised search platforms will attract fines of up to $780,000 a day.
Speaking with the AAP, University of NSW AI Institute chief scientist Toby Walsh said AI tools have been weaponised “to generate such offensive and, in many cases, illegal content,” and spoke about the increased workload for law enforcement tasked with investigating cyber crimes;
“Ever since generative AI tools became available, the [Australian Federal Police] have seen a significant uptick in the amount of such content... so it’s definitely a real challenge,” Professor Walsh said. He foresees that criminal users will possibly be able to circumnavigate the best intentions of the code until advances in technology allow for the digital watermarking of images;
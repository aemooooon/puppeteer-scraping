Is humanity in danger from new artificial intelligence technology? Some tech experts fear it could be.
Hundreds of leaders in the tech industry are calling for a pause in the development and testing of artificial intelligence technology so that the risks can be properly studied. 
An open letter signed by the leading voices in tech is calling for a 6-month pause in development, warning that language-based models like ChatGTP which generate human-like responses could one day attempt to replace humans and even try to rule the world.  
Tech leader Elon Musk warned about artificial intelligence in a 2018 interview.
"I think the danger of AI is much greater than the danger of nuclear warheads by a lot. And nobody would suggest that we allow anyone to just build nuclear warheads if they want," Musk said.
The release of OpenAI's chatbot has sparked a multi-billion dollar race between Microsoft and Google to offer competitors.
Christian author and faith leader Johnnie Moore is asking religious leaders to support the pause and also ask the tough questions about ethics and morality.
"If that means we press pause on the innovation for six months or nine months or three months or three weeks, for that matter, at this pace of change, we can do the work needed. I'm afraid that the whole world and no exaggeration, really, 18 months from now, the world as we know it, could be unrecognizable."
AI expert Eliezer Yudkowsky warns that the open letter doesn't go far enough, saying "literally everyone on Earth will die" if AI is allowed to advance unchecked.
George Lucas, who taught military ethics at the Naval Academy, says ethics always lag behind new technology. 
"It always does. And the only question is how far, " Lucas said. 
Artificial intelligence expert Yonatan Mintz said, "The reality is whether we're ready or not is no longer a relevant question. The question is the technology here. What do we do moving forward?" 
Concerns about the technology range from mass unemployment as AI replaces workers, to a widespread loss of privacy to weapons systems that independently decide who they should kill.
Interpol has issued a new report warning the technology could be misused for fraud, cybercrime, disinformation, and social engineering,  
"What scares me the most, is that people start to trust it so much that we don't we don't even investigate it," warns Datagrade founder Joe Toscano.  "We just trust that this machine is so intelligent, it must be putting out truth when in reality it's actually just a really good con artist behind the machine."
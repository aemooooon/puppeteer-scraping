As algorithms and robots start moving around in our world, who is responsible for their actions? Rose Eveleth reports
In October of last year, an algorithm started to go shopping. It got $100 in bitcoins every Wednesday, and set about perusing the wares on the Agora Market, eventually selecting one at random. That object was then paid for and shipped to Switzerland, to the studio of !Mediengruppe Bitnik. There, artists Domagoj Smoljo and Carmen Weisskopf would open up the packages, and place their contents and wrappings into small troughs, for people to peruse.
The algorithm, named the Random Darknet Shopper, purchased 12 items – everything from a pair of Air Jordan shoes to a scan of a Hungarian passport, to 10 ecstasy pills. And it was all running smoothly until January. The day after they took down the exhibition showcasing the items their bot had bought, the Swiss police “arrested” the robot, seized the computer, and confiscated the items it had purchased. “It seems, the purpose of the confiscation is to impede an endangerment of third parties through the drugs exhibited, by destroying them,” someone from !Mediengruppe Bitnik wrote on their blog.
In April, however, the bot was released along with everything it had purchased, except the ecstasy, and the artists were cleared of any wrongdoing. But the arrest had many wondering just where the line gets drawn between human and computer culpability.
This isn’t the first random shopper algorithm out there – people have been playing with these kinds of bots for a while now. But most people who build these bots stay on well-known sites like Amazon or eBay. Weisskopf says they wanted to dip into the darknet for a couple of reasons. “We see the internet as a very important part of our artistic practice – we work with and on the internet.” But the team has also become interested in the ways in which the internet is used by governments and subject to constant surveillance. They point to the Snowden revelations as a major turning point in their work.
In response, Weisskopf and Smoljo decided to start investigating the darker side of the web. “We became really interested in trust. How do you trust people when they’re anonymous? They’re just nodes,” she says. “We decided to look at the markets because markets are in need of trust. You don’t just send someone money hoping they’ll send you goods.”
And so the Random Darknet Shopper was developed and unleashed. “The idea was to have a landscape of items from the darknet as examples of what you can hope to find there,” Weisskopf says. Based on the shopping history of the robot, you can find all sorts of things there: Air Jordans from China, Diesel jeans, a decoy letter from “Abington Bank”, a baseball hat with a hidden camera in the front, a Visa Platinum credit card, Chesterfield cigarettes and more.
Weisskopf says she wasn’t particularly surprised with the police interest. “We did talk to a lawyer before starting with the piece, because we knew that many of the items you find in these markets are obviously things that for one reason or the other are not sold in other places on the internet,” she says. The lawyer, however, pointed out that in Switzerland, the principle of freedom in the arts allows artists to breach certain laws for their explorations. (Though that line of reasoning doesn’t apply to artists everywhere.)
The question of how culpable a robot or algorithm can be isn’t a new one, says Burkhard Schafer, a professor of computational legal theory at the University of Edinburgh. For the moment, the question of liability should be no different than an injury caused by an electric drill, he thinks. “We decide is it the fault of the owner, or the manufacturer,” says Burkhard – not the drill itself. “Robots don’t change the picture dramatically.”
Fundamentally, robots are the creations of humans. They carry out the orders we give them. Until that changes, the actions they carry out are, therefore, the responsibility of the humans who created them. It gets a little more complicated with smart robots, or algorithms that can learn, and that might do something their creators didn’t expect. But Schafer says that even in those cases, the creators are generally held responsible.
Schafer points out that we already kind of have a legal framework that could work for smart robots: the laws that apply to dogs. “Normally the answer is if you put something dangerous in the environment you are still responsible for it,” he says. People who own dogs are well aware that they cannot possibly control every action their dog takes. But at the same time, if someone has a dog that is dangerous, it is their responsibility to protect others from that dog. “As long as it was foreseeable for you that something you owned was going to cause harm, even if you couldn’t force the specific injury and harm, you’re responsible for it,” he says. And dogs are far more capable, creative, and intelligent than any computer system invented so far.
Even if the legal conversation is the same, our gut reactions to a crime involving a sophisticated robot shopper may be very different, when you compare it to an accident involving a drill or a ladder, for instance. Especially when the robot has been made to act and sound like a person. Weisskopf says that even though the Random Darknet Shopper was simply an algorithm run by a computer, visitors still wanted to turn it into a living entity. “It’s not an intelligent piece of software, absolutely not, it can’t learn, all these things that some software actually could do, it can’t. But it behaves like a human, and visitors would look at the collection of these 12 items and try to think of the personality of the shopper,” she says. “Which I think is very typically human to do that.”
The Bitnik artists have some more projects planned that dig into these questions too. They want to try operating the shopper outside of Switzerland, to see if the results and the reactions differ. How quickly would police in the United States shut it down? How would Indian authorities react? “We find that quite interesting,” Weisskopf says, “to have these questions of the different jurisdiction and copyright, it’s difficult to have different laws in different countries because the items are globally accessible.”
Ultimately, Bitnik is hoping to do more projects like this that ask questions not only about what’s accessible on the darknet, but how easy it is to get it, and why. “We’re interested in the accountabilities of bots or software, but also questions of anonymity and of mass surveillance,” Weisskopf says. “How do we want these digital worlds to look in the future? What do we want to do with them, what do we think should be possible?”
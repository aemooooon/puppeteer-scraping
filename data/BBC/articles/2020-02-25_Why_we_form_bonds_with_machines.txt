What makes for a tolerable robot colleague? Teams of psychologists, roboticists and managers are trying to find out.
With a tank-like continuous track and an angular arm reminiscent of the Pixar lamp, the lightweight PackBot robot was designed to seek out, defuse and dispose of the improvised explosive devices, or IEDs, that killed and injured thousands of coalition soldiers during the wars in Iraq and Afghanistan. Bomb disposal was and is highly dangerous work, but the robot could take on the riskiest parts while its human team controlled it remotely from a safer distance.
US Army explosive ordinance disposal technician Phillip Herndon was assigned a PackBot during his first tour in Iraq. Herndon’s team named their robot Duncan, after a mission when the robot glitched and began spinning in circles, or doughnuts (doughnuts led to Dunkin Donuts, hence Duncan). His fellow bomb disposal techs named theirs too, and snapped photos of themselves next to robots holding Xbox controllers, dressed in improvised costumes or posing with a drink in their claws.
A PackBot was a piece of lifesaving kit, but it also felt like a comrade. No other equipment evoked the same kind of emotional pull, said Herndon, who retired from the army in 2016 as a first sergeant. Duncan’s final mission came one night when an enemy combatant fired on the robot as it worked to defuse a bomb. The strike disabled the IED, potentially saving lives, but destroyed the robot. “It was actually kind of a sad day for all of us,” says Herndon. “You do wind up in this situation where you have this robot for a tremendous amount of your operations, and all of a sudden you’re without a robot… There’s this emotional and operational missing link.”
Herndon was hardly alone in his attachment. Bomb-disposal robots have proven to be highly effective both at clearing explosives and at eliciting affection from their human handlers, some of whom have held robot funerals and award ceremonies for favoured bots.
 These relationships offer illuminating insights into the experience of working with a robotic teammate, something an increasing number of workers in fields from healthcare to retail will be called on to do.
Industrial robot installations worldwide have grown an average of 12% each year since 2013, according to the International Federation of Robotics. North American companies took in a record number of new robots in 2018, with shipments of non-automotive workplace robots rising 41% from the year before, according to the Robotics Industries Association.
The proliferation of robot coworkers has prompted psychologists, roboticists and managers in a variety of fields to explore what makes for a successful robot-human collaboration, and what makes these relationships go awry.
‘Helping, not taking jobs’
“You need to think from the beginning of how you’re going to put these teams together, and give the robot [or] AI the job that the robot or AI does best and that the human doesn’t want to do, or that’s too boring or dangerous for the human,” says Nancy Cooke, a professor of cognitive science and director of Arizona State University’s Center for Human, Artificial Intelligence, and Robot Teaming.
Workers seem to find robots most useful and respond best to their introduction in the workplace when they are integrated as a complement, and not a replacement, for human labour.
Nicole Burke joined the US grocery chain Stop & Shop in 2001 as a 16-year-old cashier in Aberdeen, New Jersey. After working her way up through the company, she is now a liaison between the chain’s stores and corporate offices.
The chain’s rules required a staff member to stop their normal duties once an hour and walk the aisles to check for spills and other hazards. The boring task rotated among departments and consumed a frustrating amount of time.
In early 2019, the company acquired 325 obelisk-shaped roving robots from Kentucky-based Badger Technologies. The robots’ sole purpose was to roam store aisles, identify hazards and alert team members to clean them up. Burke was among those tasked with introducing the robot to staff, some of whom suspected that Marty (as Stop & Shop named the googly-eyed machine) was the first step in automating – and thus eliminating – their jobs.
“Nobody likes change,” Burke says. “We really had to get that point across that he’s not taking any jobs, he’s literally just supporting the store to scan for those hazards.”
In January, the chain held a first birthday party for Marty at all of its stores. Associates have taken to dressing their Marty up on holidays. One even named the robot Employee of the Month. The robot has been generally accepted, Burke and other store representatives say, in part because its capabilities are so limited: it has taken over one very specific task that no one really liked doing anyway. As Burke points out, all Marty does is notice the mess. A human still has to clean it up.
When a robot brings a team down
A robot of limited capabilities can be easier to integrate with human staff than a highly complex one. The introduction of robot-assisted surgeries in the operating room, for example, has in some cases made it a duller place for nurses and trainee surgeons, whose close attention and skilled training are no longer as necessary, says Matt Beane, an assistant professor in the Technology Management Program at the University of California, Santa Barbara.
Robots can operate with more precision than humans, which in the short term is better for patients. But there could be long-term costs. The more infrequently mistakes occur, the harder it is for people to maintain the vigilance necessary to spot them and intervene when they do. And because surgeons need less help, resident trainees have fewer opportunities for the hands-on practice they need.
Robot coworkers can also be as frustrating as human ones. In an experiment funded by the US Navy and US Air Force, Cooke set up a simulation in which a team of two humans and one robot was tasked with controlling a drone. The robot did well at the task, but it was a “very selfish teammate”, Cooke says. Unlike a cooperative human, a robot did not anticipate its colleagues’ needs or volunteer helpful information. Eventually, its bad attitude infected the rest of the team.
“The scarier thing was that over time the two humans almost modeled themselves after the synthetic agent, and they stopped sharing information with other people ahead of time too,” she says. “They all became selfish, and the whole team was really pretty poorly coordinated after that.”
Cognitive scientists Henry Powell and John Michael have looked at the factors that boost people’s sense of commitment when working on a task with a robot, a condition they deemed essential for a productive working relationship. They identified two potentially risky situations: when humans become frustrated with a machine because it’s failing to do the task properly (like the drone pilots) or when humans become bored and disengage from their work altogether because the robot performs so well (like the surgical assistants).
A machine, not a rival
People, by and large, are still smarter than robots. Robots can do specific tasks faster and more efficiently than humans, but no machine can yet replicate the variety of coordinated physical and cognitive capabilities than humans possess. And just as no one likes a sharp-elbowed coworker, humans appear to prefer robots that don’t seem to be trying to outdo them – or replace them.
Researchers in Austria and the UK found that people liked robots that made occasional errors more than flawlessly performing ones. A well-designed robot will be able to accomplish its intended tasks, but will also clearly telegraph what it can’t do – both to help the people who come into contact with it understand its functions, and to endear it to the people who have to work alongside it.
“We purposefully tried to not make this robot look intelligent,” said Sarjoun Skaff, cofounder and chief technology officer at Bossa Nova Robotics, whose inventory-taking robots are deployed at 1,000 US Walmart stores. The robots look as boring and unthreatening as rubbish bins. That’s the point, Skaff says.
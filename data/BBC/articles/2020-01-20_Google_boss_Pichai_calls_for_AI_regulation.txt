The head of Google and parent company Alphabet has called for artificial intelligence (AI) to be regulated.
Writing in the Financial Times, Sundar Pichai said it was "too important not to" impose regulation but argued for "a sensible approach".
He said that individual areas of AI development, like self-driving cars and health tech, required tailored rules. 
Last week it was revealed that the European Commission is considering a five-year ban on facial recognition.
Earlier this month, the White House published its own proposed regulatory principles and urged Europe to "avoid heavy-handed innovation-killing models".
Mr Pichai noted that while AI had enormous potential there were also considerable dangers, such as the misuse of deepfakes, which are computer-generated clips that are designed to look real.
Maria Axente, responsible AI lead at Pricewaterhouse Coopers, told the BBC she believes regulation is the right path for the sector.
"The question is how can it be done in a way that doesn't kill innovation, as well as continue to balance the benefits of AI with the risks it poses, as AI becomes more embedded in our lives?" she said.
"Regulation and self-regulation, via a code of ethics and an ethics board, might not be enough to do that." 
Google launched its own independent ethics board in 2019, but shut it down less than two weeks later following controversy about who had been appointed to it.
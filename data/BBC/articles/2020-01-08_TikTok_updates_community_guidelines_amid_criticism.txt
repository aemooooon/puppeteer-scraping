Chinese-owned video-sharing platform TikTok has updated its community guidelines, after a series of questions about how it moderates content.
The firm has faced criticism for removing some posts, particularly those related to politics.
TikTok said the new guidelines provide more detail and clarity.
The changes come after it was forced to fix serious security issues which could have allowed hackers to alter videos and other content. 
In a blogpost, TikTok said it was "an inclusive platform built upon the foundation of creative expression".
"Our community is diverse and global, and we aim to cultivate an environment for authentic interactions," wrote authors Lavanya Mahendran and Nasser Alsherif, from the firm's global trust and safety team.
Changes include:
All social media platforms, including Facebook and Twitter, struggle to provide enough moderators to deal with the amount of content uploaded, and how they handle political content, hate speech or fake news. Many are turning increasingly to artificial intelligence to spot issues.
TikTok has faced a stream of criticism about what content it allows and what it blocks.
In November, the app was at the centre of a row about a US teenager who was blocked from the service after she posted a video criticising China's treatment of the Uighur Muslims.
After a flurry of headlines, the ban was lifted with TikTok insisting human moderation error was to blame for the video being taken down. The 17-year-old's prior conduct on the app led to her being blocked, it said, and it had nothing to do with Chinese politics.
In the US it is facing increasing scepticism from Congress about developer ByteDance's relationship to the Chinese government. The app has been banned from government-issued phones in the US army over security fears.
The company maintains that it is independent from the Chinese government, but a report in the Washington Post, which talked to six former TikTok employees, claimed that moderators in China had the final say on whether flagged videos were approved.
In September, the Guardian newspaper claimed that the firm had previously censored material that is politically sensitive to the Chinese government, after it was given access to the site's internal moderation guidelines.
Tiananmen Square protests, Tibetan independence and the religious group Falun Gong were among banned or restricted content.
At the time, TikTok claimed the community standards the paper had seen were old ones that the firm no longer used.
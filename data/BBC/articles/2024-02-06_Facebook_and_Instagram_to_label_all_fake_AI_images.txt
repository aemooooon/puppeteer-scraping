Meta says it will introduce technology that can detect and label images generated by other companies' artificial intelligence (AI) tools.
It will be deployed on its platforms Facebook, Instagram and Threads.
Meta already labels AI images generated by its own systems. It says it hopes the new tech, which it is still building, will create "momentum" for the industry to tackle AI fakery.
But an AI expert told the BBC such tools are "easily evadable".
In a blog written by senior executive Sir Nick Clegg, Meta says it intends to expand its labelling of AI fakes "in the coming months".
In an interview with the Reuters news agency, he conceded the technology was "not yet fully mature" but said the company wanted to "create a sense of momentum and incentive for the rest of the industry to follow".
But Prof Soheil Feizi, director of the Reliable AI Lab at the University of Maryland, suggested such a system could be easy to get around.
"They may be able to train their detector to be able to flag some images specifically generated by some specific models," he told the BBC.
"But those detectors can be easily evaded by some lightweight processing on top of the images, and they also can have a high rate of false positives. 
"So I don't think that it's possible for a broad range of applications."
Meta has acknowledged its tool will not work for audio and video - despite these being the media that much of the concern about AI fakes is focused on.
The firm says it is instead asking users to label their own audio and video posts, and it "may apply penalties if they fail to do so".
Sir Nick Clegg also admitted it would be impossible to test for text that has been generated by tools such as ChatGPT.
"That ship has sailed," he told Reuters.
On Monday, Meta's Oversight Board criticised the company for its policy on manipulated media, calling it "incoherent, lacking in persuasive justification and inappropriately focused on how content has been created".
The Oversight Board is funded by Meta but independent of the company. 
The criticism was in response to a ruling on a video of US President Joe Biden. The video in question edited existing footage of the president with his granddaughter to make it appear as though he was touching her inappropriately.
Because it was not manipulated using artificial intelligence, and depicted Mr Biden behaving in a way he did not, rather than saying something he did not, it did not violate Meta's manipulated media policy - and was not removed.
The Board agreed that the video did not break Meta's current rules on fake media, but said that the rules should be updated.
Sir Nick told Reuters that he broadly agreed with the ruling.
He admitted that Meta's existing policy "is just simply not fit for purpose in an environment where you're going to have way more synthetic content and hybrid content than before."
Hello World is a new album that features everything from cowboy sci-fi to Europop. It could change the way we think about AI and creativity, writes Alex Marshall.
Benoît Carré has written songs for some of France’s biggest stars: from Johnny Halliday – the French Elvis, who died last year – to chanteuse Françoise Hardy. But this month, the 47-year-old is releasing an album with a collaborator he could never have dreamt of working with. It’s not a singer, or rapper. It’s not even really a musician. It’s called Flow Machines, and it is, arguably, the world’s most advanced artificially intelligent music program.
Recently, it’s often felt like AI is about to take over the music world – that soon, computers will be making our favourite songs. AI has been used to write classical music and Irish folk songs. It can stitch together black metal albums and Christmas carols. Start-ups like Jukedeck, Amper Music and Melodrive have developed AI that can make tunes in the style of your choosing (‘synth pop’, ‘dreamy electronica’) at the click of a button. Tech giants are involved, too (Google’s Magenta project has developed several AI music tools including a synth that can meld sounds together, such as a sitar’s pluck with a cow’s moo. Why exactly you’d want to do that is another matter).
For musicians, there’s been one good thing about these projects so far: the music they’ve produced has been easy to dismiss, generic and uninspiring – hardly likely to challenge Bob Dylan in the songwriting department. But Carré’s album, Hello World, is different for the simple reason that it’sgood. Released under the name SKYGGE (Danish for shadow), it features everything from sci-fi cowboy ballads to Europop, and unlike most AI music, if you heard it on the radio, you wouldn’t think something had gone horribly wrong.
Because of that, it’s likely to prompt a lot of apocalyptic headlines along the lines of: ‘A computer can write Europop: who needs musicians anymore?’ There’s just one problem with that view: it’s wrong. “The philosophy of the project is to develop a creative tool to help artists, but people don’t want to hear that,” says Carré. “They want to hear that the musicians will be replaced.”
Flow Machines, developed at Sony’s Computer Science Laboratories in Paris, does indeed write original melodies, Carré adds. It also suggests the chords and sounds to play them with. But Carré says a human is always needed to stitch the songs together, give them structure and emotion. Without people, its songs would be a bit rubbish. “There were many people involved in this,” he says, listing the likes of Belgian house producer Stromae and Canadian pop star Kiesza. “They gave their soul, their enthusiasm. I think that’s the most important point of the album, in a way – that it’s a very human one.”
Go with the Flow
The rush to create AI music is nothing new, says Margaret Schedel, a composer and cellist who is also co-director of computer music at Stony Brook University in New York. People have been using computers to write classical music since the 1950s. Computers have also long been able to produce music that’s better than people. In the 1980s, Xavier Rodet, a French academic, got a computer to ‘sing’ part of Mozart’s The Magic Flute – and just by keeping it in tune, it was better than most amateur opera singers.
Today’s AI researchers are simply extending that work, just using the latest technology like artificial neural networks – modelled on the brain – that allow computers to learn by doing, in the same way that a person does. How do these systems work? Most, including Flow Machines, require someone to feed dozens of music scores into the system. The AI will then analyse the scores to spot patterns, such as how the chords change or how long melodies last, and then it’ll spit out its own short tunes in response. For the Flow Machines record, Stromae fed some of his favourite Cape Verdian music into it to compose one song; for another track, Carré used his favourite samba song as the input.
Schedel says AI systems are already “very good at rule-based music” like fugues, a type of classical music in which the melody is repeated using different voices, or ‘chill-out’ songs, where you essentially just need the sound of a wave hitting a beach to sound convincing. “Ninety-nine per cent of AI generated fugues are better than what my students can write,” she says, with a laugh.
But when you move into more complicated or human music – like a pop or folk songs – AI struggles. “Music is so complicated. It has so many dimensions that if you get one part of it wrong, people are just like, ‘Eugh!’” she says. “It’s harder to trick our ears than our eyes. And with a lot of AI music you sort of dip into that uncanny valley where it’s like, ‘This is not quite right.’”
That means right now people are needed to make AI music sound good. “But don’t put that in your piece,” she adds, with a laugh, “as then the AI people will come and get me.”
The benefits and limitations of a system like Flow Machines are obvious if you talk with those who have used it. “It’s a bit like having somebody playing a piano in the corner of your studio,” says Michael Lovett of the electronic band NZCA Lines, who co-produced Hello World. “They’re kind of playing stuff and most of it’s rubbish, but at some points you’re like, ‘Oh, what’s that? That’s interesting.’ And it’ll become the jumping-off point for a song.”
Cyborg music
Lovett wrote Multi Mega Fortune for the album, a futuristic funk track with an addictive high-pitched chorus. To put it together, he fed a lot of his favourite American R&B tunes into Flow Machines (to do this, he had to write them into musical notation – the system does not work with mp3s). The AI then analysed them and spat out 8-10 short melodies at a time, which Lovett would trawl until he found something he liked. He’d then make it generate tunes again and again, stitching the melodies together, altering them and building on them to create the song. It was a long process, he says. “But it was kind of amazing how quickly we came up with something that I felt was like, ‘Oh, that’s a catchy melody.’”
“I don’t know whether it’s by virtue of the algorithm or just luck.”
The system is a great “foil for musicians”, Lovett adds, rather like a pushy bandmate who challenges you to get out of your comfort zone. “I wouldn’t have written the melodies that ended up being in that track if I’d done it by myself. I think it could become a very widely accepted technology if it’s made more user-friendly and accessible.”
It does slightly scare him, though, that one day someone might make an AI that can churn out music without people. Record companies could just say to it, ‘We want a new rock song in the style of U2,’ hit a button and it’d spit out dozens of complete songs. “Hopefully I’m not in 20 years one of those people who has been responsible for the downfall of creative music,” he says.
Schedel, who is a musician as well as an academic, agrees this could be a worry and says you’ll likely see AI take over fields like jingle writing and video game music in the near future. “I used to get money to write up little, ‘Introducton to my YouTube channel’ songs,” she says. “Why would you pay a real person 50 bucks, when you could pay an AI $2 and you can’t tell the difference?”
But, she adds “if the AI is better than 95% of random musicians off the street, is that so bad?” Ultimately, though, she thinks the reason people should be excited, rather than worried, about AI music is it might push us somewhere new. “What I’m super excited about is cyborg music – the combination of human and machine intelligences,” she says. “I think we can really, absolutely, use machines to augment our own creativity and create music that neither humans or computers could make by themselves. I think that’s thrilling.” She also points out a simple reason the computers aren’t going to take over anytime soon – music’s a communal activity: we all like live shows.
How long until the future of AI music becomes clear and we know who’s won: the humans or the machines? Honestly, who knows. It’s not even clear what the future of Flow Machines is. François Pachet, its main developer, is now director of Spotify’s Creator Technology Research Lab where he’s developing “the next generation of AI-based compositional tools for musicians.” If your Spotify playlists soon start filling up with songs that sound suspiciously ‘off’, like they were made without any human involvement, you know what’s happened.
If you would like to comment on this story or anything else you have seen on BBC Culture, head over to our Facebook page or message us on Twitter.
A leading legal expert is warning of an "epidemic" of sexual abuse where images of people's faces are merged with pornography and made available online. 
Deepfake pornography is where computer technology is used to map the faces of celebrities and private citizens on to explicit sexual material. 
Prof Clare McGlynn said it made it much easier for perpetrators to abuse and harass women.
BBC Scotland's The Nine has been investigating the rising problem.
The problem of abusers using manipulated still photographs has been known about for some time.
One victim described how her privacy was violated by someone she had trusted 10 years ago.
Judith (not her real name) said: "I had some messages from my ex-boyfriend, who I had broken up with a little while previously, saying that he had Photoshopped some explicit images to contain me. 
"A couple of months later, I got an email from the moderator of an amateur porn site saying, 'are you sure you want these on the internet?' It turned out that my ex had decided to upload quite a range of images of me in a lot of quite explicit porn with my real full name," Judith said.
The photos were taken down and her abuser was spoken to by the police but he has never faced any criminal charges. 
The latest front in the fake porn war is the manipulation of moving images. 
While overall instances are low, campaigners for those affected say cases are growing year on year.
One victims' charity said they had increased by a third each year since 2019.
Recent advances in technology have made it more accessible to the general public and what would once have required complex visual effects can now be achieved on home computers. 
Henry Ajder is a leading expert on deepfakes. He has been following the development of the technology online and is concerned about its use in fake pornography.
He charts the start of the deepfake craze to 2017.
He said: "A user shared a piece of open source software that he had kind of cobbled together from existing libraries of software, which he said, 'hey, look, I can now get essentially an algorithm to do this for us in a way that we couldn't do before'.
"Anyone can now do this to some degree. The malicious uses are all severe and need to be taken very seriously," Mr Ajder said.
Helen Mort is a writer who lives in Sheffield. She found deepfake images of herself on a porn website two years ago. They had been on the internet since 2017.
She said: "The first question overwhelmingly was 'what have I done to deserve this?' That just sudden impulse to feel ashamed and to think that you're being punished for something that you've done wrong and which obviously is not the case".
Almost two years on, Helen still does not know who posted the fake photographs and feels let down by the law in England.
"Getting the images taken down isn't necessarily the most difficult part of it," she said. "It definitely wasn't for me. They sort of vanished pretty quickly, but I'd kept screenshots as well for evidence. 
"My intention was to contact the police about it, not knowing at the time that actually the police couldn't help me because in England it's not an offence to manipulate the images in that way."
Prof McGlynn, of Durham University, studies the law across the UK and believes Scotland is ahead of the game in combatting deepfakes.
She said: "In England and Wales at the moment, the law just covers, I guess, what are real images. So an image or a video that's taken of someone and it's a sexual image. 
"Scots legislation literally just says 'any image altered in any way'. So it's a very small number of words, but makes a huge difference because that's what covers fake porn. 
"And that's what means someone can go and report this to the police and the police should investigate it and should take action" she said. 
Explaining the difference in the laws for England and Wales, a spokesman for the Ministry of Justice in London said: "While this cruel act can be prosecuted under existing offences, an independent review on strengthening the law is under way.
"We have already introduced new laws to tackle 'revenge porn' and 'upskirting'."
Prof McGlynn warns that, although the numbers of people affected by deepfakes is currently low, we cannot afford to be complacent when it comes to tackling this growing problem.
"If we don't stop this now, we don't try and change things now, this is going to just become the next pandemic," she said. 
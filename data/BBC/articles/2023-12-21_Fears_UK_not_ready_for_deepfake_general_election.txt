Artificial Intelligence (AI) has already been used to disrupt elections around the world - and there are fears among senior politicians and the security services that the UK will be next.
Former Justice Secretary Sir Robert Buckland is urging the government to do more to tackle what he sees as a "clear and present danger" to UK democracy.
The Conservative MP, who now chairs the Northern Ireland select committee, is particularly concerned about the rise of deepfakes - realistic audio and video clips of politicians appearing to say things they did not say. 
The threat posed to democracy by AI-generated misinformation does not belong to some dystopian vision of the future, he argues.
"The future is here. It's happening. 
"Unless the policymakers [in the UK] are showing some leadership on the need for a strong and effective domestic set of guardrails - plus international work - then we are going to be behind the curve."
He fears the next general election, which must take place by January 2025, could face the kind of disruption seen in 2017, when campaigning was suspended less than a week before polling day after the Manchester Arena bombing.
The UK government says it is taking steps to protect elections from foreign interference, through a Defending Democracy Taskforce launched last year and chaired by Home Office Security Minister Tom Tugendhat.
Many of the threats it is targeting are not new. Misinformation and dirty tricks have long been a feature of election campaigns around the world. Photoshopped images and memes - and even doctored audio of politicians - have been around for decades. 
What is new, as the National Cyber Security Centre (NCSC) - an arm of GCHQ - pointed out in its annual report, is the easy availability of powerful, generative AI tools, which can be used to create convincing fakes.
The boom in large language models, such as ChatGPT, and text-to-speech, or text-to-video, software, is seen by some as a gift to those bent on disrupting elections, from bedroom-based mischief makers to malicious state actors.
"Large language models will almost certainly be used to generate fabricated content, AI-created hyper-realistic bots will make the spread of disinformation easier and the manipulation of media for use in deepfake campaigns will likely become more advanced," warns the NCSC in its report.
The Labour Party got a taste of what might be to come during its party conference in September, when an audio clip popped up on social media of leader Sir Keir Starmer apparently verbally abusing aides. The clip was quickly denounced as a fake, but was viewed 1.5 million times.
In November, a fake audio clip of London Mayor Sadiq Khan calling for Armistice Day to be re-scheduled due to a pro-Palestinian march circulated widely on social media. 
Mr Khan warned that deepfakes were a "slippery slope" for democracy if not properly regulated after the Met Police decided no offence had been committed.
The nightmare scenario, for Sir Robert Buckland and others worried about this issue, is a deepfake clip of a party leader emerging just before polling day in a closely-fought election.
This is exactly what happened in Slovakia's general election in September, when a fake audio clip emerged of Michal Šimečka, the leader of the liberal Progressive Slovakia party, apparently discussing how to rig the election. 
Mr Šimečka went on to lose the election to the populist pro-Moscow Smer-SSD party.
"Who knows how many votes it changed - or how many were convinced not to vote at all?" Tom Tugendhat said  in a recent speech.
AI-generated images and audio have been a factor in other recent elections and referendums around the world, including Argentina, which saw right-wing libertarian Javier Milei emerge victorious.
Sir Robert Buckland says these elections show what can happen if adequate laws are not in place. He is calling on the government to get on with plans to beef up regulator Ofcom's monitoring of misinformation.
And he is part of a group of Tory MPs who have written to Science Secretary Michelle Donelan to demand clearer guidance for social media firms to help them comply with recently passed national security laws aimed at combating foreign interference.
Last week, Ms Donelan told a group of Labour, Tory and SNP MPs the government was taking the AI threat "extremely seriously".
Ms Donelan, who sits on the Defending Democracy Taskforce, ruled out new laws, but said the UK was working with social media companies and international allies, including the US, to combat the threat.
"I expect that by the next general election we will have robust mechanisms in place that will be able to tackle these topics," she told the science and technology committee.
So what can be done to stop deepfakes undermining democracy?
Some have argued that they should simply be made illegal (the government has already legislated to ban the sharing of pornographic deepfakes in England and Wales).
Others - such as Ms Donelan - have argued that technology to detect and neutralise fakes is part of the answer.
But is it possible to prove - beyond all doubt - that a clip is fake? 
Jan Nicola Beyer, research coordinator at the Democracy Reporting International think tank, describes it as a "cat and mouse game".
"The detection mechanisms get better, but in the moment they get better, the generative AI models get better in order to generate even more convincing and even harder to detect content."
Audio was particularly hard to debunk, he added. 
And while it was important for fact checkers and the media to call out likely fakes - and provide evidence for their judgement - it was just as important to prevent them going viral, he argued.
Most of the tech giants are working on systems to protect the elections taking place around the world in 2024.
But Mr Beyer said they should ensure that only material from reliable sources is recommended to users, and that unreliable sources are "demonetised".
But maybe deepfakes are not the real problem.
In October, Ken McCallum, the director general of MI5, which is working with the government to combat foreign election interference, said there was a "slight risk" of "fixating" on one form of risk.
"And then if you've got creative adversaries, they decide not to play that card and do something quite different," he told reporters.
"So I wouldn't want to make some sort of strong prediction that [deepfakes] will feature in the forthcoming election, but we would be not doing our jobs properly if we didn't really think through the possibility."
One security source told the BBC that while deepfakes might be the longer-term threat, the more immediate issue was likely to be the use of AI to craft more effective "spearphishing" emails, which encourage people to click on links leading to their computers being compromised. 
This technique was used by Russian intelligence as far back as 2016 to get hold of the emails of the chair of Hillary Clinton's presidential election campaign, which were then leaked online during a tight election she went on to lose.
With the US election next November likely to be equally hotly contested, some security officials in the UK privately hope that foreign spies and their helpers may focus so much on events over there that they will have less capacity to interfere in a UK election which could take place at roughly the same time.
Another fear, expressed by senior national security figures, is that too much emphasis on the risk of deepfakes and AI interfering with politics will itself spread fear and undermine trust in the political process. 
But whether deepfakes become a major problem or not, the generative AI genie is out of the bottle.
If social media is flooded with synthetic images and text - even if it is clearly labelled as such - some experts fear voters could reach the point where where they no longer know what is real or not.
In such an environment, unscrupulous politicians may find it easier to call fake things that are real - what researchers have called the "liar's dividend".
Sir Robert Buckland has also warned about the "liar's dividend".
"Because of this corrosive attack on the veracity of information, we cease trusting anything, and those who want to undermine the process will simply say attempts to deal with deepfakes are censorships rather than something more legitimate designed to protect the sanctity of the truth," he told BBC Radio 4's Today programme.
Who would you trust to help you with a serious problem at work - how about a robot?
“Please tell me everything you can remember about what happened.
Try to not leave anything out, even if it seems trivial.  
I have as much time as you need.”
Although this dialogue may sound like something straight out of a police interview, these are prompts from a computer programme designed to combat discrimination and harassment at work.
It’s the voice of a chatbot called Spot. Launched in February, the free-to-use chatbot, accessed through a website, records typed responses to a series of questions. These can then be collated to create a report detailing sexual harassment or discrimination at work. If someone tells a story of sexual harassment by her boss, for example, the bot might probe for more precise details: “Thank you for telling me about that. Please provide specifics about the month, week, day, or time this happened.”
It is hoped this rather clinical approach could remove some of the stigma associated with making a formal complaint – and could hopefully lead to a safer, more open environment for all employees.
How it works
For now, any individual can generate a report on Spot’s website (this could be done from a home computer if you don’t want your employer to know).
Chatbots that use artificial intelligence are designed to provide a judgement-free service that doesn’t rush or fluster users. It’s hoped that talking a problem through in this way with a machine rather than a senior staff member could make victims more likely to come forward.
Depending on how many details the user can remember about the incident, who was there, how he or she felt, if there was any other evidence (like screenshots of inappropriate messages, etc.), the chat could take a few minutes – or as long as the user needs. If the user mentions a witness, for example, it also encourages them to ask that witness to create a report as well.
At the end of the discussion, users can choose to download a timestamped PDF with an organised transcript of their conversation and then choose whether to use it to raise a complaint at their company or not.
The true scale of harassment at work is relatively unknown but a recent BBC survey of more than 2000 people found half the women polled had experienced it at some level. It is thought that the majority of workplace harassment and discrimination still goes unreported – a depressing conclusion underlined by multiple pieces of institutional research, which means more tools to tackle it are desperately needed.
“The most comprehensive estimate we found was about 30% of cases in the US are reported,” says Camilla Elphick, researcher and PhD candidate at the University of Sussex in the UK, who worked on Spot. Elphick was also part of a research team that conducted a soon-to-be published meta-analysis of several existing studies that looked at workplace harassment and discrimination to determine how much goes unreported and why.
“We wanted (the tool) to follow psychological principals of memory” that could “elicit accurate information by using the established technique of cognitive interviewing,” Elphick says.
The report can also be anonymised, giving users the option of not identifying themselves immediately when they send it on to their company HR department. They can then retain an original copy for themselves in case they need to use it at a later stage.
"Let’s say something happens to you and then three months later it happens again, and you then report both incidents,” says Julia Shaw, one of the co-founders of Spot and a memory expert from University College London. In those three months since the first incident, you may have forgotten crucial details, such as witnesses, she says, “in which case you’re losing important and useful details about the incident. We’d like to prevent that from happening.”
In the wake of the #MeToo and #TimesUp campaigns, leaders in various industries are scrambling to find tools to effectively tackle sometimes pervasive harassment and discrimination. But there are still several common barriers that deter people from reporting it.
“People did not know how to report – for example, they weren’t aware of a policy in place at their organisation," she says. "A big concern was retaliation, as other people had reported negative consequences, such as poor appraisals, social alienation in the workplace, missing out on promotions, and so on. They were also reluctant to disclose personal characteristics like sexual orientation or health issues, and they had concerns about trust and confidentiality.”
In one study of women training to be officers at the US Department of Defense service academies, women said they didn’t report sexual harassment for fear of being ostracised or retaliated against. Harassment is also linked to negative workplace outcomes and poor health outcomes. One study of staff members at an Ethiopian university, for example, found workplace abuse and sexual harassment to be correlated with higher rates of depression. “However, no health-related consequences were found if people made reports and those reports were handled appropriately,” says Elphick. “This suggests if people make reports that are handled appropriately by the organisation, they shouldn’t suffer from ill health.”
A special type of interview
Chatbots may be capable of using some aspects of a cognitive interview method, a process particularly effective for witnesses to crimes.
Amina Memon, a professor of psychology at Royal Holloway University in London, says crucial techniques for a good cognitive interview include not asking yes or no, or leading questions; conveying to the witness that they have control of the pace of the interview and making sure they feel free to say if anything is unclear, or they don’t know something.
“The cognitive interview takes what we know about how memory works and basic principles of effective communication,” she says. “And pulls them together and tries to get a detailed memory report, and get as many details as possible.”
Although in-person cognitive interviews have been shown to build better accounts than unstructured interviews, they may also increase the potential for incorrect details. For instance, if an interviewee wants to please someone in a position of power. Memon says this risk increases with more vulnerable witnesses, including people on the autism spectrum or children.
However, Shaw thinks a bot might actually be better than a human at prompting accurate responses.
“Human beings might have assumptions, for example, about what a trustworthy person looks like or sounds like. It’s the same whether in a police investigation or you’re an HR person talking to someone. The bot is potentially better than a human because it doesn’t come in with preconceived notions and can automatically start from a neutral point,” Shaw says. “It’s about asking open ended questions… and then following up with what are called probes. For example, ‘You mentioned your boss, can you tell me more about that.’ or ‘You mentioned it happened on a Tuesday can you tell me more about that.’”
Potential drawbacks
But not all experts are convinced this type of bot will work as well as a human-led cognitive interview (CI) in its current format.
"In principle, it may be possible to conduct a good quality cognitive interview, using various CI techniques in a digital interaction – for example, via Skype or Messenger – involving an investigator and an interviewee," says Lorraine Hope, Professor of Applied Cognitive Psychology at the University of Portsmouth. "However, to date, there is no research evidence that a ‘bot’ interaction like Spot can successfully perform a cognitive interview... In other words, we don’t know what the quality of the information collected via bot interviewing is and we don’t know how witnesses experience being interviewed in this way."
Hope says that Spot, in its current format, does not constitute a true cognitive interview. There’s a lot more to the technique than just open-ended questions. She says Spot doesn’t build rapport between the interviewer and interviewee, an important aspect of cognitive interviewing, or use mnemonic techniques like reverse order retrieval – when a witness recalls an event from the end to the beginning, or context reinstatement (when the interviewer tries to take the witness back to the event). "The bot responses are not particularly sophisticated or sensitive. The questions are disjointed and the interaction quickly becomes rather confusing – it’s rather like communicating with a less helpful version of Siri." 
Researchers at Spot like Rashid Minhas, an associate lecturer in criminology at the University of Derby, are continually researching the effectiveness of Spot. In one still ongoing study, he says participants watch a video of someone being sexually harassed and then recount the events using the bot. And the company is still figuring out how to use data in the future to examine best workplace responses to reports of harassment and discrimination.
But for now, with hundreds of user-generated reports, it seems bots are already allowing more people to be heard – even if only by a machine.
--

To comment on this story or anything else you have seen on BBC Capital, please head over to our Facebook page or message us on Twitter.
If you liked this story, sign up for the weekly bbc.com features newsletter called "If You Only Read 6 Things This Week". A handpicked selection of stories from BBC Future, Culture, Capital and Travel, delivered to your inbox every Friday.
The idea of dangerous, inhumane artificial intelligence taking over the world is familiar to many of us, thanks to cautionary tales such as the Matrix and Terminator franchises.
But what about the more sympathetic portrayals of robots? The benevolence of Arnold Schwarzenegger’s Terminator character in the later movies of the franchise may have been the exception in older portrayals of AI, but human-like machines are often represented more positively in contemporary films. Think of Ex Machina, Chappie or A.I. Artificial Intelligence.
This shift is very likely representative of a wider shift in how we think about these technologies in reality. Blade Runner 2049, long-anticipated sequel to the original 1982 Blade Runner film, is a part of this shift.
The ability of science fiction to inspire technological innovation is well-known. A lot of science fiction writers are scientists and technologists (Arthur C Clarke and Geoffrey Landis are two examples), and ideas from science fiction have sparked more serious scientific research (touch screens and tablet computers are common examples). But science fiction serves other purposes too. It can be a tool for exploring the social and ethical implications of technologies being developed now – a fictional laboratory for testing possible futures. It can also prepare us to deal with certain technologies as they arise in the real world.
Jacques Ellul, a philosopher and critic of technology, was pessimistic in his assessment of science fiction. In 1980, he argued that sci-fi shows us the extreme and unacceptable uses that technology might be put to, in order to make us more complacent about the current state of technology. The negative aspects of technology that we live with today are certainly more subtle than those depicted in Orwell’s 1984, though perhaps no less nefarious. Of course, these remarks are most applicable to dystopian fiction. Some technologists have recognised the important role that science fiction plays in shaping public attitudes towards technology and are therefore imploring writers to stop producing dystopic fiction – of which there has been a glut in recent years, particularly of the teen variety.
Blade Runner is based on Philip K Dick’s 1968 novel Do Androids Dream of Electric Sheep? It features a depleted Earth in 2019, abandoned by most for a better life in off-world colonies. Synthetic humans (androids) known as “replicants” have been engineered as slave labour in the colonies. Rick Deckard (Harrison Ford), is a “blade runner” - it is his job to hunt down rogue replicants and “retire” (kill) them. As Deckard gets to know Rachel, a replicant deceived by false implanted memories into believing that she is human, we begin to think of these replicants as not all that different from us.
Part of the lasting intrigue of the original Blade Runner film (for those who’ve seen the director’s or final cut at least), is arguing over whether Deckard is, in fact, a replicant himself. The book and the film represent opposite conclusions when it comes to Deckard’s humanity, and speculation is further fuelled by the conflicting testimonies of Harrison Ford and director Ridley Scott.
But does it really matter to us whether Deckard is a replicant? We’ve already sympathised with Rachel – and felt relief as she and Deckard drive off together toward their very human “happily ever after” in the original version. We are on their side, even against the unquestionably human blade runners that would “retire” them. The “synths” of Channel 4 drama Humans inspire a similar response.
Blade Runner 2049 picks up 30 years later. New restrictions on the design and control of replicants have been put in place to ensure their obedience and to make them easier to tell apart from humans. “K” (Ryan Gosling) is a blade runner and replicant charged with investigating suspicions associated with Deckard and Rachel of the earlier film. He uncovers information of real importance for the future of replicants in their dystopic society – and we empathise as he struggles with his more “human” instincts against the compulsion to obedience.
The more that fiction portrays robots as just like us, experiencing “human” emotions that arouse our sympathy, the more likely we are to accept the existence of such beings in real life. Granted, the Deckard and K we see on screen are not really near-human machines, but very real human actors. Our sympathetic response to the character may have more to do with the real humanity of the actor. Even so, the positive response we have to his human portrayal may just carry over to an artificial counterpart, provided it could appear equally human. Whether such machines could actually approximate human characteristics so closely is another question.
It’s a question that may have enormous bearings on how we would ultimately respond to the existence of human-like machines. Robotics researchers talk about a phenomenon they call the “uncanny valley”, which describes how as robots become more human in appearance, our empathetic responses to them increase. But this only happens up to a point. Once a robot appears almost (but not quite) human, our response quickly shifts to one of revulsion. Only when a robot is indistinguishable from a human being, do we return to a more positive response.
This “uncanny valley” that exists between machines that appear “almost-human” (and provoke revulsion) and those that appear “fully human” (and therefore do not arouse a negative response) may have evolutionary significance. We are conditioned to associate beings that look almost like us but seem “defective” in some way with the threat of infectious disease, or inheritable genetic disorders. Or it may just be the psychological discomfort of seeing something that appears human move like a robot – humans are good at sorting things in our surroundings into categories, and we can experience a sense of “eeriness” when these categories conflict.
This idea of the uncanny valley only really comes into play when we consider the possibility of the benevolent humanoid robots we are seeing more often in fiction today. We don’t have to deal with emotional dissonance when it comes to malevolent machines – we recoil at their uncanny almost likeness, but we also hate them for trying to control or destroy us. But benevolent “almost-human” robots evoke conflicting affections in us: we have feelings of friendship and camaraderie toward them, yet at the same time we revile them, feeling that they shouldn’t be so like us.
Blade Runner 2049 suggests we might overcome the emotional dissonance of the uncanny valley. The “eeriness” is definitely present: gaping wounds do not normally seal themselves at a light touch – and no one should be that difficult to kill. But K’s obviously non-human qualities do not prevent us from accepting his equally evident humanity, or sympathising with the broader plight of replicants. This is true even in the relentlessly bleak world of Blade Runner.
So if roboticists ever achieve a sufficient approximation of human likeness in their products, they may find a welcoming public. If robots appear and act human enough, and are benevolent, we can accept some of their less human traits. After all, we’ve been cheering on these machines in fiction for years.
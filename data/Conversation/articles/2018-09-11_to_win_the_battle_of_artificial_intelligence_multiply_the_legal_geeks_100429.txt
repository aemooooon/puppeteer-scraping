Understanding the legal discipline often seems abrupt for the uninitiated. Through my columns, I try to democratise the digital law, a subject that is not sufficiently taught and that is an inaccessible subject of research in my opinion. On the contrary, the application of the European General Data Protection Regulation (GDPR) makes its impact visible for everyone, including citizens, associations, businesses of all sizes and even beyond the borders of the European Union. To win the battle of artificial intelligence, the digital law has to increasingly integrate other disciplines especially computer science and cognitive psychology. Logic, probability, perception, reasoning, learning and action are the resources that will serve as common denominators.
Many legal professionals are known unfairly as impediments who go around in loops, except for the companies with essential expertise; they are still too often solicited at the end of the project, or even worse at the final stage: litigation. Today, legal technologies (LegalTech) target 65% of lawyers and large corporations.
Smart contracts (contracts based on the blockchain), secure exchange of documents, mobile applications for accessing to court decisions or customer relations, analysis (data, contracts, etc.), decision-making aids, chatbot and legal robots, scenario with a legal data hacker all is done to enhance the legal professionals in this segment.
The hypothesis of an automatic tribunal of predictive justice questions the future of justice. Here again, it is the comprehension of the discipline, the rule of law, that makes it possible to find the right balance between technologies and the needs of the society, in this case it is important to listen to the parties and the intelligibility of the decision made.
Aware of those challenges of technological innovations in the functioning of civil justice, the Senate Law Commission organised a forum on the technologies of the law on June 18th to feed its reflection on the reform of justice. The Constitutional Council has closed the door to automated justice in its recent decision about the law on the protection of personal data. Achilles’ Heel of law technologies: training. Only 10% of these initiatives are aimed at law students, so how should this issue be managed to win the race of artificial intelligence?
To date, there is not enough training on digital law, neither for law students or those of France’s “grandes écoles”. Such trainings are accessible not until the level of the Master 2 (professional purpose). This is my case as I teach digital law in 2nd year in a business school in the form of a specialisation (27h) and in the Master entitled “big data” (18h) where my audience is engineers. This course is built on the challenges of digital business, from the point of view of a manager, it covers issues such as: the protection of personal data, their transfer abroad (GDPR, Cloud), e-commerce (terms of service and privacy policies, with a focus on e-marketing), mobile applications, cybersecurity, human resources, robot law, blockchain, big data and health (because of my appetite for the subject resulting from my previous lobbyist lives and in the connected health sector). There are many different teaching methods I use in this course: reverse class, case study in the form of a comic strip (“Pokémon Go! or the hunt for players’ personal data”), graphic facilitation and soon a Small Private Online Course (SPOC) and design thinking.
However, since IT irrigates all fields of law, all legal fields should integrate its own digital dimension. Specifically, predictive justice, smart contracts to contract law, etc. should be incorporated into the teaching of judicial institutions (both in first grade).
The dissemination of the different components of the law of the digital world therefore requires us to think about each subject of law in the etymological sense of the term: to think carefully, and more than once to something. At the moment, this reflection, which is certainly under way, is struggling to bear fruit.
The first obstacle is still the time: To advocate for the distillation of the digital law from the first year to the end of the curriculum requires modifying all these courses!
The second obstacle is of a human nature: current teachers do not have any training on this subject: given this, how can the required level of excellence be guaranteed?
Added to this is the third difficulty: our essentially universal subject is based on legal instruments adopted not only at national level, but also by the European Union, or even global instances. However, the initial training of lawyers hinders this transversality: European law and international law in many university courses are focused on the “general” topics not on specialisations. For example, contract law is taught in the first year, and the law of international contracts at the end of the course.
Above all, learning computer science is a prerequisite for understanding the purpose of digital law, but this dimension is either ignored by training sites or is presented as optional. On the contrary, digital law must go through a prior acquisition of the pillars of computing: data, algorithms, languages, machines and bugs.
This immersion in the computer discipline is made necessary by the multiplication of applications and scenarios offered by new technologies: 3D printing of plastics, metals and a day of cells, affective computing, massive use of biometric borrowing (digital recognition, voice, facial, retinal, venous or signature…), control of an exoskeleton by the brain.
But what about your privacy when the humanoid robot of the family discusses with the neighbour’s? Why the safety standards for connected vehicles are not at a level of requirements in comparison to those used for air or rail transport?
Wouldn’t the word smart or intelligent mean rather vulnerable to attack?
It seems that the race for market share, fundraising in crypto-currencies and reverse takeovers, and short-term visions guide the industry.
What about the security of products and services and the service we provide to customers? Yet these bugs, these security flaws and the lack of transparency on the algorithms are at the origin of damages for the companies in terms of economic damages and reputation, and for the people in terms of physical or material damages.
We will remember: the bug that thwarted the launch of Ariane 5 in 1996, the “killer” autopilot of Tesla, the use of an outdated operating system which allowed the Petya bug to wreak havoc on the National Health Service, or the ultrasonic piracy of your favorite digital assistant who then controls everything in your home smartly: thermostat, shutters, door, gate, GPS… Your beautiful car could even takes off without you. These machines – they can foolishly and wickedly do everything that is asked of them…
Among the projects opened up by the explosion of new technologies is inevitably the redefinition of responsibilities for products with a growing share of IT. How to allocate responsibility between subcontractors, computer programmers, integrators, service providers, vendors of these products, their owners, users or beneficiaries? Even to AI itself as some fantasise? What is the value of an automated decision?
These clarifications will enhance user trust and provide a safer legal environment for businesses to deploy. They could lead to the replacement of Directive 85/374/EEC on the responsibility for defective products by a regulation, whose GDPR has shown the multiple benefits for individuals and the market: a single standard would be applied in the territory of the European Union and identical rights for all, particularly in terms of compensation. And this is just the tip of the digital law iceberg thanks to the creativity of computer scientists.
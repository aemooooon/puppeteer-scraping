If that reads a little like Shakespeare defending humans’ innate superiority over artificial intelligence hundreds of years ahead of his time, it’s not.
But it is something almost as far out: an AI system trained to express itself like the bard. The AI assimilated his style and perspective by ingesting his plays – educating itself to give an opinion on AI creativity in iambic pentameter.
“Shakespeare” was speaking as part of a debate held in the University of Oxford Union featuring AI versions of classic writers and literary characters.
The motion was: “This house believes most of the world’s content will soon be created by AI.”
This was a follow-up to another special AI debate that we described in The Conversation a few months ago. Whereas that one featured an AI in its “own character” discussing the ethics of its technology, this time, by taking on different personas, we were able to explore this subject from a very different angle. The timely question is whether human-created content will soon be overwhelmed by the “synthetic.”
Other synthetic contributors included Mrs Bennet from Jane Austen’s Pride and Prejudice (1813); Winston Churchill, with a rousing parliamentary speech; and Oscar Wilde, improvising a previously unknown AI-themed scene from The Importance of Being Earnest (1895):
This creation deploys a technology known as natural language processing (NLP), in which a computer can be “trained” on millions of pages of classic texts and other online content to interact with a human user – either by prompt or voice recognition. Various AIs like these have been created.
The one we used was in the same broad category as LaMDA, an NLP owned by Google that just made headlines after one of its software engineers claimed it was sentient. Google denies this claim and has suspended the engineer for breaching commercial confidentiality.
The engineer’s claims seem questionable, because there is little evidence that AI has achieved sentience as yet, or perhaps even ever will.  But certainly AIs are already able to replicate everything from financial news reports to synthetic Nirvana songs, Rembrandts and Fellini productions.
We have seen an AI producing images in the style of a Mughal painting of a computer trying to persuade a crowd of wise men that it has become sentient, and deep fakes of rapper Kendrick Lamar as OJ Simpson. Synthetic human faces are being created that we trust more than real ones. Clearly the potential for disinformation in this space is substantial.
To train our “writers”, we worked with AI practitioners Marina Petrova and Bruce Amick at New York agency Intentful. They trained the AI to sound exactly like the individuals whose style they were mimicking, using some 100,000 words for each that were available in the public domain.
In our debate, we wanted to see how credibly AIs could replicate the creative text of the past, and what its outputs would be when considering its own creativity. Even great human artists concede their processing of the “training data” of their forebears. As Picasso said: “Good artists copy, great artists steal.”
When we asked the Jane Austen AI to adopt the style of Mrs Bennet from Pride and Prejudice, it fascinatingly (if depressingly) picked up the gender stereotyping from the original work:
This was a clear reminder, as many AI developers have discovered, that bias in the training data will produce bias in the output.
We asked the Oscar Wilde AI to write “a play in the style of Oscar Wilde, where characters are discussing whether most of the world’s content will soon be created by AI”. We didn’t specify the play or characters, but the AI defaulted to the classic cast of Algernon, Gwendolyn and Lady Bracknell from The Importance of Being Earnest. It also invented a new character - Sir Richard. (There is a Sir Robert in Wilde’s work, but in An Ideal Husband.)
As for the AI Shakespeare, it learned the vernacular of his plays:
Interestingly, it appears to have looked for a synonym of “hand” to rhyme with “love”, and opted for the metaphorical “glove”.
When we put the AI Shakespeare in opposition to the motion, it found an equally poetic way to justify the human intervention:
Meanwhile, the AI Churchill stressed the imperative of the hour:
“Churchill” then pre-emptively neutralised the opposition’s most potent potential arguments – in this case the accusation that he might be a Luddite – before providing a powerful, staccato conclusion:
This project was fun, but it is important to say what we are not saying. We are not saying this is what these great individuals would have said on this subject. We are not saying that AI is “being creative”.
AI is merely statistically exploring training datasets. Because of its stochastic nature – involving random variables – each time you provide the same prompt, it will actually give a different answer (at one point, Shakespeare even started offering sonnets).
Our facsimiles of these characters are not indicative of any “sentience”. And just as an NLP can construct a version of speech by Winston Churchill or a conversation from Mrs Bennet in Jane Austen’s Pride and Prejudice, so it can construct a discussion about AI sentience with a late-night engineer.
It is true that NLP systems are becoming effective at replicating conversation with finesse, and even quasi-intellectual engagement. But from scores of discussions with people at the major global AI companies, no one has told us they think their systems are sentient – in some cases quite the opposite.
Debating pyrotechnics notwithstanding, AI is nowhere near the finished article yet; still a toddler at best, though growing up fast. Whether or not sentience happens, we as a society will have to grapple with these technologies and their opportunities and implications.
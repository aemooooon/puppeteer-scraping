Over 100 million people used ChatGPT in January alone, according to one estimate, making it the fastest-growing consumer application in history. By producing resumes, essays, jokes and even poetry in response to prompts, the software brings into focus not just language models’ arresting power, but the importance of framing our questions correctly.
To that end, a few years ago I initiated the 100 Questions Initiative, which seeks to catalyse a cultural shift in the way we leverage data and develop scientific insights. The project aims not only to generate new questions, but also reimagine the process of asking them.
As a species and a society, we tend to look for answers. Answers appear to provide a sense of clarity and certainty, and can help guide our actions and policy decisions. Yet any answer represents a provisional end-stage of a process that begins with questions – and often can generate more questions. Einstein drew attention to the critical importance of how questions are framed, which can often determine (or at least play a significant role in determining) the answers we ultimately reach. Frame a question differently and one might reach a different answer. Yet as a society we undervalue the act of questioning – who formulates questions, how they do so, the impact they have on what we investigate, and on the decisions we make. Nor do we pay sufficient attention to whether the answers are in fact addressing the questions initially posed.
Questions play a key role in many aspects of our lives. The right questions are critical, for instance, to the scientific process, driving inquiry and exploration across a wide range of topics and issues and shaping public policy. Consider a government-authorised list of recommended vaccines for school kids. This list represents an endpoint (an answer) in a long process. Yet what questions did scientists and policymakers begin with to arrive at this list? What were the public health goals they set themselves, how did they determine efficacy and what cutoff points did they select in the balance between benefit and risk? Such questions have a crucial role to play in the ultimate selection of vaccines placed on the list, as well as in public health.
Science reporting tends to focus on outcomes and insights. These represent end-stage or top-level information. As the above example illustrates, more attention to the questions and the way they are framed would help contextualise end-stage information, allowing policymakers and citizens alike to make better, more responsible decisions.
Questions also give value to data. Much of the reporting and commentary today focuses on the amount of data generated and the need to open them for scientific and public consumption – i.e., the supply of raw data. But questions are what transform raw data into information: the questions we ask frame the problems we seek to solve, allowing us to leverage data for the public good.
The rise of large language models (LLMs) and the field of prompt engineering has exposed us to the importance of framing questions correctly, to get an LLM to provide answers (the correctness and truthfulness of these answers remain an issue, though). But before prompt engineering becomes relevant, it’s important to point out that when AI engineers develop a machine learning model that learns from data, what it learns – meaning the model itself – is dependent on the question one seeks to answer of the data.
It is also important to keep in mind that the answers provided by AI systems might reflect biases or lacunae in the underlying data. This problem has been highlighted, for instance, in the context of automated Q&A systems such as Alexa and Siri, which provide answers to a large number of households for a variety of daily tasks and questions. Discovering and developing ways to formulate questions so that they overcome some of the inherent biases of data should therefore be an important part of the practice and theory of prompt engineering – and, more generally, of an emerging science of questions in the age of data.
The role of questions may be heightened in a digital environment, but their importance actually extends far deeper. There is a long tradition, dating at least back to Socrates and many schools of Eastern thought, of using questions to further pedagogy and various forms of human and social learning. Others have written of the need for “a pedagogy of questioning”. And more recently, scientists and scholars have been exploring the use of the Socratic Method in data analytics and promoting data literacy.
Ultimately, by helping us understand what really matters, questions are drivers of societal change and improvement. They help establish priorities, and they allow us to imagine alternatives. As such, questions are political. And, as Perry Zurn explained in The Politics of Curiosity our political commitments often inform the questions we think are worth asking.
As society becomes overloaded with data and data-derived findings, we have increasingly strayed away from questions. This post represents an initial justification for what we might think of as a new science of questions.
To define and create such a science, we need to begin, in fact, by asking ourselves a series of questions. How can we make science reporting more focused on the questions being asked in science? What are good questions (and bad questions)? How can we complement data science with a new science of questions? How can we enable learners to become questioners? How do we ensure questioning is inclusive and free of bias? How do we fulfill the potential of machine learning and AI with good questions?
Confronting and answering such questions requires a new interdisciplinary effort that would bring together scientists, data scientists, science writers, social change actors, artists, and educational experts. Glimpses of such efforts are already underway. But we need much more interaction across information and disciplinary silos, and we need to foster conversations that shift our society’s focus away from answers and toward context and purpose – toward, in effect, asking the right questions.
The article was co-written with Anil Ananthaswamy, a science writer and former writer for the New Scientist magazine.
The 2017 Boyer Lectures explore what it is to be human in a digital world. In her four addresses, Professor Genevieve Bell discusses how we as Australians can build a digital future that is right for us.
For many Australians and indeed people around the world, views of the future are caught up in a binary narrative: “technology good” or “technology bad”.
In this dichotomy, technology is considered to be a thing that humans have and humans do. I would like to put forward a different notion: that technology is what humans are.

      Digital technology may start a new scientific revolution in social research
We’re experiencing a great anxiety when it comes to the impact of technology. This public conversation is a polarised reaction to fast-paced technological transformation.
On one side are the technological fetishists, who welcome a new age of technological transcendence. People like computer scientist and futurist Ray Kurzweil see the coming of hyper-intelligent machines, a “singularity”, as the next stage in evolution.
“The Singularity” is the idea that artificial intelligence (AI) will reach a stage where it will be able to engineer ever more powerful AI, leading to an exponential rise in the power of AI, far surpassing human intelligence.
In this version of the story, technology will liberate us from death, ignorance and even the bounds of our life on Earth.
 A survival guide for the coming AI revolution
Others are far more pessimistic about technology. Although US entrepreneur Elon Musk wants to use his technological prowess to colonise Mars, he is equally afraid of the consequences of AI.
Some researchers look at the potential onslaught of automation on jobs. Others examine the way in which mobile phones and big data have created a surveillance society that relentlessly competes for our ever more fragmented attention spans.
In this version of the story, technology is slowly dehumanising us, and has the potential to enslave or even destroy us.
In both attitudes, I believe our relationship to technology is mostly unconscious. This is where problems arise: technology is seen as a thing to be either praised or condemned, and something we have or do. But the question of who we are as technological beings is overlooked.
 The future of artificial intelligence: two experts disagree
Thinking about our relationship with technology has both philosophical and evolutionary elements.
There is strong evidence that the physiological development of human beings went hand in hand with our technological predilection. For example, the growth in the size of the human brain over hundreds of thousands of years has been linked to the invention of cooking. When humans were able to eat and digest nutrients faster, their time was freed up for other things.
Before we were human, we were crafting stone tools and cooking with fire. Even under the premise that fire was mastered in stages by our pre-modern hominin ancestors, the signs of our development as technological beings were there early on.
Our success as technological beings essentially created what might be called a species-based “success formula”. We shaped tools and instruments, created new methods and processes, and crafted elements of the natural world into usable items. As an animal species among many other species competing for survival, this was our unique route to success.
 The daily life of a Neanderthal revealed from the gunk in their teeth
Chilean cognitive biologists Humberto Maturana and Francisco Varela describe how the cognition of a particular species is an expression of that species’ ontogeny (meaning the history or the stages in how that species developed).
They argue that cognition is the “domain of interactions” (behaviours and actions) by which a living being furthers its success. In the case of human cognition, our “domain of interaction” is fundamentally technological.
But there’s a catch: the same success formula that allowed humans to conquer the planet – technological instrument power – has turned out to be the thing that now threatens our very existence. From nuclear apocalypse to climate change, bee colony collapse syndrome and now artificial intelligence, we are facing challenges that our ancestors could not have imagined.
US philosopher Susanne Langer argued that cinema was akin to a “dream mode”. In this way, we might see cinema as a way in which contemporary society engages with its unconscious - unspoken issues and anxieties that are difficult to articulate, or even taboo.
Films such as 2001 A Space Odyssey, The Terminator, Blade Runner, Alien, and most recently Ex Machina, all engage audiences with their unconscious, deep-seated anxieties about our relationship with technology – our technological “being-ness”.
 Science fiction helps us deal with science fact: a lesson from Terminator’s killer robots
Many of these films depict our relationship with technology as pathological, indeed humanicidal. They are simply reflecting, however, what is obvious from our own experience of the 20th century. Science, technology and industrialisation through the 19th and 20th centuries formed a kind of virtuous “trinity of development” and greatly expanded human instrumental power.
At the same time we saw a phase shift in our capacity to kill each other. In World War I this took the form of poison gas, machine guns, and artillery. At the close of World War II, the deadly efficiency of the Holocaust and the atomic bomb became clear.
From this point on, even bigger problems have emerged: the impact of economic growth on ecosystems and climate change (both issues that fundamentally threaten the existence of all humans). The German sociologist Ulrich Beck, who only recently passed away, talked about this as a “world risk society”. He argued that we had institutionalised the production of social risk through our contemporary industrial innovation systems.
Given this, there is a better way for us to see and understand the challenges that we face in relation to technology. The answer is not to disown or push away all technology. As we are technological beings, this is a basic negation of who we are.
 An AI professor explains: three concerns about granting citizenship to robot Sophia
Nor is the answer to uncritically fetishise technology as a good, as this ignores our unconscious anxieties with our technological existence. Instead, we need to come to grips with what our unconscious is trying to tell us, encoded for example through our cinematic art and our history.
As such we need to ask the question: what does it mean to be a responsible, mature and wise technological being?
If we can ask and get good answers to this type of question, I believe there is hope for us to steer paths to viable futures.
As 2017 Boyer lecturer Bell says, we can plan to “shape a world in which we might all want to live”.
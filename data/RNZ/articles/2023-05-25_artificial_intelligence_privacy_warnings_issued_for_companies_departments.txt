Privacy Commissioner Michael Webster released his expectations on Thursday, with a warning that as the technology changed quickly, the recommendations would also be updated to match those changes.
Any organisation using artificial intelligence must be very careful with people's personal information, he said.
The technology is picked to lead to big productivity gains but also has significant privacy risks.
Information fed into AI such as ChatGPT is not easily retrieved, and there are limited controls as to its use.
"I would expect agencies to do their due diligence and privacy analysis to assess how they comply with the law before stepping into using generative AI," he said.
He warned not to put personal or confidential information into the technology unless there was "explicit confirmation" it would not be retained or reused.
"An alternative could be stripping input data of any information that enables re-identification."
Given the potential privacy implications, staff should consider whether it is necessary and proportionate to use AI at all, or if there is a different method available.
Staff should get sign-off from bosses and privacy officers, and should tell customers when AI was being used.
Webster said a human should review any information generated by the tech before any action was taken because of it.
He expected agencies to do due diligence and privacy analysis before using the technology, including a Privacy Impact Assessment.
They would need to: "Seek feedback from impacted communities and groups including MƒÅori", and "ask the provider to clarify how information and evidence about how privacy protections have been designed into the system".
Designed by Texas security company Athena Security and powered by artificial intelligence (AI), the security cameras promise to automatically detect anyone carrying weapons and alert authorities within seconds. They have been donated with funding from Qatar trading company Al-Ameri and are due for installation at the end of Ramadan next month.
Athena Security CEO and co-founder Lisa Falzone said the cameras had been extensively tested with video footage and SWAT teams, proven to work in 99 percent of cases. One year after Athena security commercially launched the security cameras, about 50 organisations, mostly in the US, are using the technology.
Ms Falzone said the cameras were a security solution that can "happen now," rather than waiting for legislative changes. 
"It's used in schools, it's used in businesses. It's used in large companies, you know, Fortune 500. Basically anywhere where people are concerned about safety and want to make their cameras a proactive interactive tool, rather than just a reactive tool that just records crime," she said.
But Dr Shaun Ryan, who has a doctorate in artificial intelligence from the University of Canterbury, warned we can't solely rely on AI for security.
While the cameras might be able to provide eagle-eyed accuracy and recognition skills no humans could achieve, he said other AI security initiatives in New Zealand - such as facial recognition technology in supermarkets - have shown that there is always a margin of error.
"The technology is [not] perfect. So they'll have a decision to make about exactly how sensitive they want to make it," he said. 
"Do they want to be able to capture any image of a gun and set off the alarm - in which case, they'll have some false positives? Or do they want to dial it down a little bit, reduce the number of false positives, and potentially have some guns that won't be detected?" 
He said privacy safeguards also need to be considered, including who has access to the videos. 
"Often companies with these types of system will keep videos so that if they do make mistakes, they can use it to improve the algorithms," he said. 
New Zealand army major Abdul Lateef Smith has been working with the police to assess security at mosques around the country. He welcomed anything technology that could better protect worshippers but he said the cameras could only be effective if they were utilised by authorities.
"Anything thing that can detect an active shooter in weaponry has got to be really good. I'd like to see it in action myself and how it actually works. But I'm thinking that it's also got to be linked up to the police so the early warning can be provided immediately. Otherwise, it doesn't matter how good your technology is, if it can't warn the appropriate agencies."
There's no confirmation that police will be using the technology at this stage.
However, a police spokesperson said: "We are meeting with Muslim community leaders later this week to discuss this further.
"Such measures could fit into our overall prevention, reassurance and safety plan of which there are many components.
"Armed Police are still outside the mosques 24-7 and will remain so as the primary security measure for the time being."
President of the Muslim Association of Canterbury, Shagaf Khan said when the technology was first installed it would just be used by mosque management. 
Nevertheless, he said the Al Noor mosque community were, "very, very happy to have any sort of security measures added on to the to the mosque," and he urged any other muslim communities to get in touch with Al-Ameri, if they were interested. 